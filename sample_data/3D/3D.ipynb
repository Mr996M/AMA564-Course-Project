{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3D",
   "id": "e3c2d1c9abdc9241"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define problem, initial and boundary conditions",
   "id": "76256b84bdc9723"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-19T08:03:34.676845Z",
     "start_time": "2025-04-19T08:03:30.689108Z"
    }
   },
   "source": [
    "\n",
    "import time\n",
    "import wandb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import pi, exp\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "n_dim = 3\n",
    "\n",
    "#Fix seeds\n",
    "random_seed = 29\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\PINN\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:03:36.163916Z",
     "start_time": "2025-04-19T08:03:36.141939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Sampler_IBC():\n",
    "    def __init__(self, lb, ub, cond=None, N_points=100,\n",
    "                 method='sobol', grid=None, split=False, DTYPE='float64'):\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.cond = cond\n",
    "        self.DTYPE = DTYPE\n",
    "        self.sample(N_points, method, grid, split)\n",
    "\n",
    "    def sample(self, N_points, method, grid, split):\n",
    "        if method == 'uniform':\n",
    "            x_ibc = np.random.uniform(0, 1, size=(N_points, self.ub.shape[0]))\n",
    "            x_ibc = self.lb + (self.ub - self.lb)*x_ibc\n",
    "        elif method == 'latin':\n",
    "            from pyDOE import lhs\n",
    "            x_ibc = self.lb + (self.ub - self.lb)*lhs(self.ub.shape[0],N_points)\n",
    "        elif method == 'sobol':\n",
    "            import sobol\n",
    "            x_ibc = sobol.sample(dimension=self.ub.shape[0], n_points=N_points)\n",
    "            x_ibc = self.lb + (self.ub - self.lb)*x_ibc\n",
    "        elif method == 'equi':\n",
    "            x_ibc = np.linspace(self.lb, self.ub, N_points)\n",
    "        elif method == 'grid':\n",
    "            x_ibc = np.linspace(self.lb, self.ub, N_points).T\n",
    "            temp_final = list()\n",
    "            for val in x_ibc[0]:\n",
    "                temp_final.append( [val] )\n",
    "            dim = 1\n",
    "            while dim < x_ibc.shape[0]:\n",
    "                temp = list()\n",
    "                for t1 in range(x_ibc.shape[1]):\n",
    "                    for t2 in range(len(temp_final)):\n",
    "                        temp_val = temp_final[t2].copy()\n",
    "                        temp_val.append( x_ibc[dim, t1] )\n",
    "                        temp.append( temp_val )\n",
    "                temp_final = temp\n",
    "                dim += 1\n",
    "            x_ibc = np.array(temp_final)\n",
    "        elif method == 'grid_old':\n",
    "            idx = np.random.choice(range(grid.shape[0]),N_points,replace=False)\n",
    "            x_ibc = grid[idx]\n",
    "        if self.cond != None:\n",
    "            y_ibc = self.cond(x_ibc)\n",
    "            self.y = tf.cast(tf.Variable(y_ibc, trainable=False ),\n",
    "                             self.DTYPE)\n",
    "        if split:\n",
    "            x_ibc, t_ibc = x_ibc[:, :-1], x_ibc[:, -1:]\n",
    "            self.t = tf.cast(tf.Variable(t_ibc, trainable=False ),\n",
    "                             self.DTYPE)\n",
    "        self.x = tf.cast(tf.Variable(x_ibc, trainable=False ),\n",
    "                         self.DTYPE)\n"
   ],
   "id": "e4357570c5f3f568",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:03:38.424083Z",
     "start_time": "2025-04-19T08:03:38.409083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Define global variables\n",
    "r = 0.01\n",
    "T = 3\n",
    "K = 10\n",
    "sigma = [[0.05, 0.01, 0.1], [0.01, 0.06, -0.03], [0.1, -0.03, 0.4]]\n",
    "sigma = np.array(sigma)\n",
    "if np.linalg.det(sigma) != 0:\n",
    "    if np.allclose(sigma, sigma.T):\n",
    "        if np.all(np.linalg.eigvals(sigma) > 0):\n",
    "            print('No problem with Covariance Matrix')\n",
    "        else:\n",
    "            print('Matrix is not positive semidefinite')\n",
    "    else:\n",
    "        print('Matrix is not symmetric')\n",
    "else:\n",
    "    print('Matrix is singular')\n",
    "\n",
    "d = np.array([r]*n_dim) - np.array([0]*n_dim)\n",
    "alphas = np.zeros((n_dim, n_dim))\n",
    "for i in range(n_dim):\n",
    "    alphas[i, i] = np.sum( np.dot(sigma[i], sigma[i]) )\n",
    "    for j in range(i):\n",
    "        alphas[i, j] = alphas[j, i] = np.sum( np.dot(sigma[i], sigma[j]) )\n",
    "DTYPE = 'float32'\n",
    "\n",
    "#Define domain boundaries\n",
    "lb = np.array( ([0.]*n_dim)+[0] )\n",
    "ub = np.array( ([3.*K]*n_dim)+[T] )\n"
   ],
   "id": "f46cafc514f722fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problem with Covariance Matrix\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:03:42.363003Z",
     "start_time": "2025-04-19T08:03:41.132216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Problem Definition\n",
    "def h_2(inp):\n",
    "    res = - np.ones( inp.shape[0] )\n",
    "    return res\n",
    "\n",
    "def g(inp):\n",
    "    res = list()\n",
    "    for inp_val in inp:\n",
    "        res.append( np.max([0,\n",
    "                            K*np.exp(-r*(T-inp_val[-1]))-\\\n",
    "                            np.min(inp_val[:-1])]) )\n",
    "    return np.array(res)\n",
    "\n",
    "def u_0(inp):\n",
    "    res = list()\n",
    "    for inp_val in inp:\n",
    "        res.append( np.max([0, K - np.min(inp_val[:-1])]) )\n",
    "    return np.array(res)\n",
    "\n",
    "def s_0(inp):\n",
    "    res = np.ones( (inp.shape[0], n_dim) ) * K\n",
    "    return np.array(res)\n",
    "\n",
    "#Point sampling\n",
    "N_to_sample = 9000\n",
    "\n",
    "#---------------- PDE Conditions\n",
    "print('PDE COnditions\\n')\n",
    "#Initial\n",
    "init_sampler = Sampler_IBC(np.array( ([0.]*n_dim)+[T] ),\n",
    "                           np.array( ([3.*K]*n_dim)+[T] ),\n",
    "                           u_0, 4000, DTYPE=DTYPE )\n",
    "print( f'x: {init_sampler.x.shape}     y: {init_sampler.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "lb_dir = ([0.]*n_dim)+[0]; lb_dir[0] = 3.*K\n",
    "dir_sampler = Sampler_IBC(np.array( lb_dir ),\n",
    "                          np.array( ([3.*K]*n_dim)+[T] ),\n",
    "                          g, N_to_sample//n_dim, DTYPE=DTYPE )\n",
    "for dim in range(1, n_dim):\n",
    "    lb_dir = ([0.]*n_dim)+[0]; lb_dir[dim] = 3.*K\n",
    "    temp_sampler = Sampler_IBC(np.array( lb_dir ),\n",
    "                              np.array( ([3.*K]*n_dim)+[T] ),\n",
    "                              g, N_to_sample//n_dim, DTYPE=DTYPE )\n",
    "    dir_sampler.x = tf.concat([dir_sampler.x, temp_sampler.x], axis=0)\n",
    "    dir_sampler.y = tf.concat([dir_sampler.y, temp_sampler.y], axis=0)\n",
    "print( f'x: {dir_sampler.x.shape}     y: {dir_sampler.y.shape}' )\n",
    "\n",
    "#Neumann\n",
    "print('No')\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "print('\\nFree Boundary COnditions\\n')\n",
    "#Initial\n",
    "init_fb_sampler = Sampler_IBC(np.array([T]), np.array([T]),\n",
    "                              s_0, 1, DTYPE=DTYPE )\n",
    "print( f't: {init_fb_sampler.x.shape}     y: {init_fb_sampler.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "dir_fb_sampler = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             None, N_to_sample, DTYPE=DTYPE )\n",
    "print( f't: {dir_fb_sampler.x.shape}' )\n",
    "\n",
    "#Neumann\n",
    "neu_fb_sampler = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             None, N_to_sample, DTYPE=DTYPE )\n",
    "print( f't: {neu_fb_sampler.x.shape}' )\n",
    "\n",
    "#---------------- Conditions passed to PINN\n",
    "pinn_conditions = {'Initial':init_sampler,\n",
    "                   'Dirichlet':dir_sampler,\n",
    "                   'Neumann':None}\n",
    "fb_conditions = {'Initial':init_fb_sampler,\n",
    "                 'Dirichlet':dir_fb_sampler,\n",
    "                 'Neumann':neu_fb_sampler}\n"
   ],
   "id": "e59febbe99bb0c1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE COnditions\n",
      "\n",
      "x: (4000, 4)     y: (4000,)\n",
      "x: (9000, 4)     y: (9000,)\n",
      "No\n",
      "\n",
      "Free Boundary COnditions\n",
      "\n",
      "t: (1, 1)     y: (1, 3)\n",
      "t: (9000, 1)\n",
      "t: (9000, 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:03:44.549643Z",
     "start_time": "2025-04-19T08:03:44.463388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "test_sampler = Sampler_IBC(lb, ub, cond=None, DTYPE=DTYPE,\n",
    "                           N_points=1000000, method='uniform', split=True)\n",
    "\n",
    "#Point sampling\n",
    "sample_to_test = 1000\n",
    "\n",
    "#---------------- PDE Conditions\n",
    "print('PDE COnditions\\n')\n",
    "#Initial\n",
    "init_sampler_test = Sampler_IBC(np.array( ([0.]*n_dim)+[T] ),\n",
    "                           np.array( ([3.*K]*n_dim)+[T] ),\n",
    "                           u_0, sample_to_test, DTYPE=DTYPE, method='uniform' )\n",
    "print( f'x: {init_sampler_test.x.shape}     y: {init_sampler_test.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "lb_dir = ([0.]*n_dim)+[0]; lb_dir[0] = 3.*K\n",
    "dir_sampler_test = Sampler_IBC(np.array( lb_dir ),\n",
    "                          np.array( ([3.*K]*n_dim)+[T] ),\n",
    "                          g, sample_to_test//n_dim, DTYPE=DTYPE, method='uniform' )\n",
    "for dim in range(1, n_dim):\n",
    "    lb_dir = ([0.]*n_dim)+[0]; lb_dir[dim] = 3.*K\n",
    "    temp_sampler = Sampler_IBC(np.array( lb_dir ),\n",
    "                              np.array( ([3.*K]*n_dim)+[T] ),\n",
    "                              g, sample_to_test//n_dim, DTYPE=DTYPE, method='uniform' )\n",
    "    dir_sampler_test.x = tf.concat([dir_sampler_test.x, temp_sampler.x], axis=0)\n",
    "    dir_sampler_test.y = tf.concat([dir_sampler_test.y, temp_sampler.y], axis=0)\n",
    "print( f'x: {dir_sampler_test.x.shape}     y: {dir_sampler_test.y.shape}' )\n",
    "\n",
    "#Neumann\n",
    "print('No')\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "print('\\nFree Boundary COnditions\\n')\n",
    "#Initial\n",
    "init_fb_sampler_test = Sampler_IBC(np.array([T]), np.array([T]),\n",
    "                              s_0, 1, DTYPE=DTYPE, method='uniform' )\n",
    "print( f't: {init_fb_sampler_test.x.shape}     y: {init_fb_sampler_test.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "dir_fb_sampler_test = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             None, sample_to_test, DTYPE=DTYPE, method='uniform' )\n",
    "print( f't: {dir_fb_sampler_test.x.shape}' )\n",
    "\n",
    "#Neumann\n",
    "neu_fb_sampler_test = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                                  None, sample_to_test//n_dim, DTYPE=DTYPE, method='uniform' )\n",
    "print( f't: {neu_fb_sampler_test.x.shape}' )\n",
    "\n",
    "#---------------- Conditions passed to PINN\n",
    "pinn_cond_test = {'Initial':init_sampler_test,\n",
    "                   'Dirichlet':dir_sampler_test,\n",
    "                   'Neumann':None}\n",
    "fb_cond_test = {'Initial':init_fb_sampler_test,\n",
    "                 'Dirichlet':dir_fb_sampler_test,\n",
    "                 'Neumann':neu_fb_sampler_test}\n"
   ],
   "id": "e002a9bdea54a2fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE COnditions\n",
      "\n",
      "x: (1000, 4)     y: (1000,)\n",
      "x: (999, 4)     y: (999,)\n",
      "No\n",
      "\n",
      "Free Boundary COnditions\n",
      "\n",
      "t: (1, 1)     y: (1, 3)\n",
      "t: (1000, 1)\n",
      "t: (333, 1)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:03:51.358835Z",
     "start_time": "2025-04-19T08:03:48.656400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#---------------- PDE Conditions\n",
    "# initial\n",
    "init_S_t = init_sampler.x.numpy()\n",
    "init_P = init_sampler.y.numpy()\n",
    "init_header = \"1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price, time, price\"\n",
    "init_data = np.hstack([init_S_t, init_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"3D_init_data.csv\", init_data, delimiter=\", \", header=init_header)\n",
    "\n",
    "# dirichlet\n",
    "dir_S_t = dir_sampler.x.numpy()\n",
    "dir_P = dir_sampler.y.numpy()\n",
    "dir_header = \"time, 1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price, price\"\n",
    "dir_data = np.hstack([dir_S_t, dir_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"3D_dir_data.csv\", dir_data, delimiter=\", \", header=dir_header)\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "# initial_fb\n",
    "init_fb_S_t = init_fb_sampler.x.numpy()\n",
    "init_fb_P = init_fb_sampler.y.numpy()\n",
    "init_fb_header = \"time, 1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price\"\n",
    "init_fb_data = np.hstack([init_fb_S_t, init_fb_P])\n",
    "np.savetxt(f\"3D_init_fb_data.csv\", init_fb_data, delimiter=\", \", header=init_fb_header)\n",
    "\n",
    "# dirichlet_fb\n",
    "dir_fb_header = \"underlying asset price\"\n",
    "dir_fb_data = dir_fb_sampler.x.numpy()\n",
    "np.savetxt(f\"3D_dir_fb_data.csv\", dir_fb_data, delimiter=\", \", header=dir_fb_header)\n",
    "\n",
    "# neumann_fb\n",
    "neu_fb_data = neu_fb_sampler.x.numpy()\n",
    "neu_fb_header = \"underlying asset price\"\n",
    "np.savetxt(f\"3D_neu_fb_data.csv\", neu_fb_data, delimiter=\", \", header=neu_fb_header)\n",
    "\n",
    "############## test ##############\n",
    "#---------------- PDE Conditions\n",
    "# the whole data\n",
    "test_data = test_sampler.x.numpy()  #only underlying asset price, without time\n",
    "test_header = \"1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price\"\n",
    "np.savetxt(f\"3D_test_data.csv\", test_data, delimiter=\", \", header=test_header)\n",
    "\n",
    "# initial_test\n",
    "init_test_S_t = init_sampler_test.x.numpy()\n",
    "init_test_P = init_sampler_test.y.numpy()\n",
    "init_test_header = \"1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price, time, price\"\n",
    "init_test_data = np.hstack([init_test_S_t, init_test_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"3D_test_init_data.csv\", init_test_data, delimiter=\", \", header=init_test_header)\n",
    "\n",
    "# dirichlet_test\n",
    "dir_test_S_t = dir_sampler_test.x.numpy()\n",
    "dir_test_P = dir_sampler_test.y.numpy()\n",
    "dir_test_header = \"time, 1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price, price\"\n",
    "dir_test_data = np.hstack([dir_test_S_t, dir_test_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"3D_test_dir_data.csv\", dir_test_data, delimiter=\", \", header=dir_test_header)\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "# initial_fb_test\n",
    "init_fb_test_S_t = init_fb_sampler_test.x.numpy()\n",
    "init_fb_test_P = init_fb_sampler_test.y.numpy()\n",
    "init_fb_test_header = \"time, 1st underlying asset price, 2nd underlying asset price, 3rd underlying asset price\"\n",
    "init_fb_test_data = np.hstack([init_fb_test_S_t, init_fb_test_P])\n",
    "np.savetxt(f\"3D_test_init_fb_data.csv\", init_fb_test_data, delimiter=\", \", header=init_fb_header)\n",
    "\n",
    "# dirichlet_fb_test\n",
    "dir_fb_test_data = dir_fb_sampler_test.x.numpy()\n",
    "dir_fb_test_header = \"underlying asset price\"\n",
    "np.savetxt(f\"3D_test_dir_fb_data.csv\", dir_fb_test_data, delimiter=\", \", header=dir_fb_header)\n",
    "\n",
    "# neumann_fb_test\n",
    "neu_fb_test_data = neu_fb_sampler_test.x.numpy()\n",
    "neu_fb_test_header = \"underlying asset price\"\n",
    "np.savetxt(f\"3D_test_neu_fb_data.csv\", neu_fb_test_data, delimiter=\", \", header=neu_fb_test_header)\n"
   ],
   "id": "195def5ff6bd290a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PINN",
   "id": "b521694bf2c76d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:39:31.150048Z",
     "start_time": "2025-04-18T17:39:31.134048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Define PDE\n",
    "def pde(tape, vars, fun_val, fo_grads):\n",
    "    second_order = 0\n",
    "    first_order = 0\n",
    "    zero_order = 0\n",
    "    zero_order += tape.gradient(fun_val, vars[-1]) - r * fun_val\n",
    "    for i, var in enumerate(vars[:-1]):\n",
    "        dx_i = fo_grads[i]\n",
    "        first_order += d[i] * var * dx_i\n",
    "        second_order +=\\\n",
    "        tape.gradient(dx_i, var) * (var**2) * alphas[i, i]\n",
    "        for j, var2 in enumerate(vars[:i]):\n",
    "            second_order +=\\\n",
    "            2*( tape.gradient(dx_i, var2) * var * var2 * alphas[i, j])\n",
    "    f = second_order/2 + first_order + zero_order\n",
    "    del(tape)\n",
    "    return f\n"
   ],
   "id": "d83a4a3d8fc9e214",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:39:32.945089Z",
     "start_time": "2025-04-18T17:39:32.761510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import GradientTape as G_Tape\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.initializers import GlorotNormal, GlorotUniform\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "\n",
    "class FreeBoundary_PINN():\n",
    "\n",
    "    def __init__(self, params, pde, ibc_cond, ibc_fb_cond, lb, ub,\n",
    "                 N_f=10000, N_fb_ibc=150, DTYPE='float64', coll_points=None):\n",
    "        self.params = params\n",
    "        self.DTYPE = DTYPE\n",
    "        self.Default_Params()\n",
    "        #Set seed\n",
    "        if self.params['seed'] != None:\n",
    "            tf.keras.utils.set_random_seed( self.params['seed'] )\n",
    "            tf.config.experimental.enable_op_determinism()\n",
    "        #Define pde\n",
    "        self.pde = pde\n",
    "        #Define intial and boundary conditions\n",
    "        self.ibc_cond = ibc_cond\n",
    "        self.ibc_fb_cond = ibc_fb_cond\n",
    "        #All needed for points sampling\n",
    "        self.lb = tf.Variable(lb, trainable=False)\n",
    "        self.ub = tf.Variable(ub, trainable=False)\n",
    "        if coll_points == None:\n",
    "            self.N_f = N_f\n",
    "            self.Sample_Points()\n",
    "        else:\n",
    "            self.x_f = coll_points[0]\n",
    "            self.t_f = coll_points[1]\n",
    "        self.N_fb_ibc = N_fb_ibc\n",
    "        #Initialize the class: define the network\n",
    "        self.Define_Regularizer()\n",
    "        self.Define_Initializer()\n",
    "        self.Define_Optimizer()\n",
    "        self.Create_Network()\n",
    "        self.Create_FB_Network()\n",
    "\n",
    "    def Default_Params(self):\n",
    "        target = self.params.keys()\n",
    "        if 'seed' not in target:\n",
    "            self.params['seed'] = None\n",
    "        if 'optimizer' not in target:\n",
    "            self.params['optimizer'] = 'Adam'\n",
    "        if 'fb_optimizer' not in target:\n",
    "            self.params['fb_optimizer'] = 'Adam'\n",
    "        if 'reg_type' not in target:\n",
    "            self.params['reg_type'] = None\n",
    "        if 'initializer' not in target:\n",
    "            self.params['initializer'] = 'glorot_normal'\n",
    "        if 'activation' not in target:\n",
    "            self.params['activation'] = 'tanh'\n",
    "        if 'output_act' not in target:\n",
    "            self.params['output_act'] = 'linear'\n",
    "        if 'pde_weight' not in target:\n",
    "            self.params['pde_weight'] = 1.\n",
    "        if 'sup_weight' not in target:\n",
    "            self.params['sup_weight'] = [1., 1., 1.]\n",
    "        if 'fb_weight' not in target:\n",
    "            self.params['fb_weight'] = [1., 1., 1.]\n",
    "        if 'patience' not in target:\n",
    "            self.params['patience'] = np.inf\n",
    "        if 'sample_method' not in target:\n",
    "            self.params['sample_method'] = 'uniform'\n",
    "        if 'fb_output_act' not in target:\n",
    "            self.params['fb_output_act'] = 'linear'\n",
    "        if 'fb_activation' not in target:\n",
    "            self.params['fb_activation'] = 'tanh'\n",
    "        if 'verbose' not in target:\n",
    "            self.params['verbose'] = 1\n",
    "        if 'steps_fb_per_pde' not in target:\n",
    "            self.params['steps_fb_per_pde'] = 1\n",
    "        if 'fb_freezing' not in target:\n",
    "            self.params['fb_freezing'] = None\n",
    "\n",
    "    def Define_Regularizer(self):\n",
    "        if self.params['reg_type'] == 'l1':\n",
    "            self.regularizer = l1( self.params['reg'] )\n",
    "        elif self.params['reg_type'] == 'l2':\n",
    "            self.regularizer = l2( self.params['reg'] )\n",
    "        elif self.params['reg_type'] == 'l1_l2':\n",
    "            self.regularizer = l1_l2( self.params['reg'][0],\n",
    "                                      self.params['reg'][1] )\n",
    "        else:\n",
    "            self.regularizer = None\n",
    "\n",
    "    def Define_Initializer(self):\n",
    "        if self.params['initializer'] == 'glorot_normal':\n",
    "            self.initializer = GlorotNormal()\n",
    "        elif self.params['initializer'] == 'glorot_uniform':\n",
    "            self.initializer = GlorotUniform()\n",
    "        else:\n",
    "            self.initializer = None\n",
    "\n",
    "    def Define_Optimizer(self):\n",
    "        temp = self.params['optimizer']\n",
    "        if temp.lower() == 'adam':\n",
    "            self.opt = Adam( self.params['lr'] )\n",
    "        elif temp.lower() == 'rmsprop':\n",
    "            self.opt = RMSprop( self.params['lr'] )\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer {temp} not recognized\")\n",
    "\n",
    "        temp = self.params['fb_optimizer']\n",
    "        if temp.lower() == 'adam':\n",
    "            self.fb_opt = Adam( self.params['fb_lr'] )\n",
    "        elif temp.lower() == 'rmsprop':\n",
    "            self.fb_opt = RMSprop( self.params['fb_lr'] )\n",
    "        else:\n",
    "            raise ValueError(f\"fb_Optimizer {temp} not recognized\")\n",
    "\n",
    "    def Create_Network(self):\n",
    "        input_layer = Input(shape=self.params['layers'][0],\n",
    "                            name = 'Input')\n",
    "        x = Dense(units=self.params['layers'][1],\n",
    "                  activation=self.params['activation'],\n",
    "                  kernel_initializer=self.initializer,\n",
    "                  kernel_regularizer=self.regularizer,\n",
    "                  name='Dense_1')(input_layer)\n",
    "        for layer in range(2, len(self.params['layers'])-1):\n",
    "            x = Dense(units=self.params['layers'][layer],\n",
    "                      activation=self.params['activation'],\n",
    "                      kernel_initializer=self.initializer,\n",
    "                      kernel_regularizer=self.regularizer,\n",
    "                      name=f'Dense_{layer}')(x)\n",
    "        output = Dense(units=self.params['layers'][-1],\n",
    "                       activation=self.params['output_act'],\n",
    "                       kernel_initializer=self.initializer,\n",
    "                       kernel_regularizer=self.regularizer,\n",
    "                       name='Output')(x)\n",
    "        self.mdl = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    def Create_FB_Network(self):\n",
    "        input_layer = Input(shape=self.params['fb_layers'][0],\n",
    "                            name = 'Input')\n",
    "        x = Dense(units=self.params['fb_layers'][1],\n",
    "                  activation=self.params['fb_activation'],\n",
    "                  kernel_initializer=self.initializer,\n",
    "                  kernel_regularizer=self.regularizer,\n",
    "                  name='Dense_1')(input_layer)\n",
    "        for layer in range(2, len(self.params['fb_layers'])-1):\n",
    "            x = Dense(units=self.params['fb_layers'][layer],\n",
    "                      activation=self.params['fb_activation'],\n",
    "                      kernel_initializer=self.initializer,\n",
    "                      kernel_regularizer=self.regularizer,\n",
    "                      name=f'Dense_{layer}')(x)\n",
    "        output = Dense(units=self.params['fb_layers'][-1],\n",
    "                       activation=self.params['fb_output_act'],\n",
    "                       kernel_initializer=self.initializer,\n",
    "                       kernel_regularizer=self.regularizer,\n",
    "                       name='Output')(x)\n",
    "        self.fb = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    def Sample_Points(self):\n",
    "        #According to the selected method, sample collocation points\n",
    "        method = self.params['sample_method']\n",
    "        if method == 'latin':\n",
    "            from pyDOE import lhs\n",
    "            cps = self.lb + (self.ub - self.lb)*lhs(self.ub.shape[0], self.N_f)\n",
    "        elif method == 'uniform':\n",
    "            cps = np.random.uniform(0, 1, size=(self.N_f, self.ub.shape[0]))\n",
    "            cps = self.lb + (self.ub - self.lb)*cps\n",
    "        elif method == 'sobol':\n",
    "            import sobol\n",
    "            cps = sobol.sample(dimension=self.ub.shape[0], n_points=self.N_f)\n",
    "            cps = self.lb + (self.ub - self.lb)*cps\n",
    "        else:\n",
    "            raise ValueError(f'Sampling method {method} not recognized')\n",
    "        #Return collocation points as tf tensors\n",
    "        self.x_f_total = tf.cast(tf.Variable(cps[:, :-1], trainable=False),\n",
    "                           self.DTYPE)\n",
    "        self.t_f_total = tf.cast(tf.Variable(cps[:, -1:], trainable=False),\n",
    "                           self.DTYPE)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self):\n",
    "        with G_Tape(watch_accessed_variables=False) as mdl_tape:\n",
    "            #Watch solution weights\n",
    "            mdl_tape.watch(self.mdl.trainable_variables)\n",
    "            #--------------- Compute Free Boundary losses\n",
    "            with G_Tape(watch_accessed_variables=False) as fb_tape:\n",
    "                #Watch free boundary weights\n",
    "                fb_tape.watch(self.fb.trainable_variables)\n",
    "                #Compute Initial Free Boundary Condition\n",
    "                fb_init = self.fb(self.ibc_fb_cond['Initial'].x,\n",
    "                                      training=True)\n",
    "                fb_init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(fb_init-self.ibc_fb_cond['Initial'].y)\n",
    "                    )\n",
    "                #Compute Dirichlet Free Boundary Condition\n",
    "                if self.ibc_fb_cond['Dirichlet'] != None:\n",
    "                    #Compute Free Boundary values\n",
    "                    s_values = self.fb(self.ibc_fb_cond['Dirichlet'].x,\n",
    "                                       training=True)\n",
    "                    fb_dc = self.mdl(tf.concat(\n",
    "                        [s_values,\n",
    "                         self.ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                         training=True)\n",
    "                    fb_dir_target = tf.nn.relu(\n",
    "                        tf.ones_like(\n",
    "                            s_values[:,-1]\n",
    "                            ) * K - tf.math.reduce_min(s_values, axis=1)\n",
    "                    )\n",
    "                    fb_dir_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(fb_dc - fb_dir_target)\n",
    "                        )\n",
    "                else:\n",
    "                    fb_dir_loss = 0\n",
    "                #Compute Neumann Free Boundary Condition\n",
    "                if self.ibc_fb_cond['Neumann'] != None:\n",
    "                    s_values = self.fb(self.ibc_fb_cond['Neumann'].x,\n",
    "                                       training=True)\n",
    "                    with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                        neu_fb_tape.watch(s_values)\n",
    "                        pinn_nc_fb = self.mdl(\n",
    "                            tf.concat([s_values,\n",
    "                                       self.ibc_fb_cond['Neumann'].x],\n",
    "                                      axis=1),\n",
    "                                      training=True)\n",
    "                    pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                                      s_values)\n",
    "                    fb_neu_target = -tf.one_hot(\n",
    "                        tf.math.argmin( s_values, axis=1),\n",
    "                        depth=n_dim\n",
    "                        )\n",
    "                    fb_neu_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(pinn_nc_fb-fb_neu_target)\n",
    "                        )\n",
    "                else:\n",
    "                    fb_neu_loss = 0\n",
    "                #Compute final loss\n",
    "                fb_loss = self.params['fb_weight'][0] * fb_init_loss +\\\n",
    "                self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "                self.params['fb_weight'][2] * fb_neu_loss\n",
    "            #Compute gradient and apply optimizers for free boundary\n",
    "            gradient_fb = fb_tape.gradient(fb_loss,\n",
    "                                          self.fb.trainable_variables)\n",
    "            self.fb_opt.apply_gradients( zip(gradient_fb,\n",
    "                                          self.fb.trainable_variables) )\n",
    "\n",
    "            #--------------- Compute PINN losses\n",
    "            #Compute unsupervised loss\n",
    "            s_values = self.fb(tf.concat([self.t_f_total], axis=-1),\n",
    "                               training=False)\n",
    "            temp = tf.reduce_sum(tf.cast(self.x_f_total < s_values,\n",
    "                                         dtype=self.DTYPE),\n",
    "                                axis=-1) < tf.ones(self.t_f_total.shape[0])\n",
    "            x_f = self.x_f_total[ temp ]\n",
    "            t_f = tf.reshape(self.t_f_total[ temp ], (-1,1) )\n",
    "            variables = list()\n",
    "            derivatives = list()\n",
    "            for i in range(x_f.shape[1]):\n",
    "                variables.append( x_f[:, i:i+1] )\n",
    "            variables.append( t_f )\n",
    "            with G_Tape(persistent=True,\n",
    "                        watch_accessed_variables=False) as pinn_tape:\n",
    "                #Watch independet variables\n",
    "                for var in variables:\n",
    "                    pinn_tape.watch( var )\n",
    "                pinn_tape.watch(t_f)\n",
    "                u_val = self.mdl(tf.concat(variables, axis=1),\n",
    "                                    training=True)\n",
    "                u_x = pinn_tape.gradient(u_val, x_f)\n",
    "                for i, var in enumerate(variables[:-1]):\n",
    "                    derivatives.append( pinn_tape.gradient(u_val, var) )\n",
    "            unsup_loss = tf.reduce_mean(tf.square(\n",
    "                self.pde(pinn_tape, variables, u_val, derivatives) ))\n",
    "            #Compute Initial Condition\n",
    "            pinn_init = self.mdl(self.ibc_cond['Initial'].x,\n",
    "                                training=True)\n",
    "            if len(pinn_init.shape) > 1:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  tf.expand_dims(self.ibc_cond['Initial'].y,\n",
    "                                                 axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  self.ibc_cond['Initial'].y )\n",
    "                    )\n",
    "            #Compute Dirichlet Boundary Condition\n",
    "            if self.ibc_cond['Dirichlet'] != None:\n",
    "                pinn_dc = self.mdl(self.ibc_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                if len(pinn_dc.shape) > 1:\n",
    "                    dir_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(pinn_dc -\\\n",
    "                                      tf.expand_dims(self.ibc_cond['Dirichlet'].y,\n",
    "                                                     axis=-1 ) )\n",
    "                        )\n",
    "                else:\n",
    "                    dir_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(pinn_dc -\\\n",
    "                                      self.ibc_cond['Dirichlet'].y )\n",
    "                        )\n",
    "            else:\n",
    "                dir_loss = 0\n",
    "            #Compute Neumann Boundary Condition\n",
    "            if self.ibc_cond['Neumann'] != None:\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_tape:\n",
    "                    neu_tape.watch(self.ibc_cond['Neumann'].x)\n",
    "                    pinn_nc = self.mdl(tf.concat([self.ibc_cond['Neumann'].x,\n",
    "                                                  self.ibc_cond['Neumann'].t],\n",
    "                                                axis=1),\n",
    "                                        training=True)\n",
    "                pinn_nc = neu_tape.gradient(pinn_nc, self.ibc_cond['Neumann'].x)\n",
    "                neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc-self.ibc_cond['Neumann'].y)\n",
    "                    )\n",
    "            else:\n",
    "                neu_loss = 0\n",
    "\n",
    "            #--------------- Compute total loss\n",
    "            pinn_loss = (self.params['pde_weight'] * unsup_loss) +\\\n",
    "            self.params['sup_weight'][0] * init_loss +\\\n",
    "            self.params['sup_weight'][1] * dir_loss +\\\n",
    "            self.params['sup_weight'][2] * neu_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "        #Compute gradient and apply optimizers\n",
    "        gradient = mdl_tape.gradient(pinn_loss,self.mdl.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(gradient,self.mdl.trainable_variables))\n",
    "        #Return losses\n",
    "        final_fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "        final_pinn_loss = unsup_loss + init_loss +\\\n",
    "         dir_loss + neu_loss + fb_dir_loss + fb_neu_loss\n",
    "        return (unsup_loss, init_loss, dir_loss, neu_loss, fb_init_loss,\n",
    "                fb_dir_loss, fb_neu_loss, final_fb_loss, final_pinn_loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_mdl_solo(self):\n",
    "        with G_Tape(watch_accessed_variables=False) as mdl_tape:\n",
    "            #Watch solution weights\n",
    "            mdl_tape.watch(self.mdl.trainable_variables)\n",
    "            #--------------- Compute Free Boundary losses\n",
    "            #Compute Initial Free Boundary Condition\n",
    "            fb_init = self.fb(self.ibc_fb_cond['Initial'].x,\n",
    "                                  training=True)\n",
    "            fb_init_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_init-self.ibc_fb_cond['Initial'].y)\n",
    "                )\n",
    "            #Compute Dirichlet Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Dirichlet'] != None:\n",
    "                #Compute Free Boundary values\n",
    "                s_values = self.fb(self.ibc_fb_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                fb_dc = self.mdl(tf.concat(\n",
    "                    [s_values,\n",
    "                      self.ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                      training=True)\n",
    "                fb_dir_target = tf.nn.relu(\n",
    "                    tf.ones_like(\n",
    "                        s_values[:,-1]\n",
    "                        ) * K - tf.math.reduce_min(s_values, axis=1)\n",
    "                )\n",
    "                fb_dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(fb_dc - fb_dir_target)\n",
    "                    )\n",
    "            else:\n",
    "                fb_dir_loss = 0\n",
    "            #Compute Neumann Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Neumann'] != None:\n",
    "                s_values = self.fb(self.ibc_fb_cond['Neumann'].x,\n",
    "                                    training=True)\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                    neu_fb_tape.watch(s_values)\n",
    "                    pinn_nc_fb = self.mdl(\n",
    "                        tf.concat([s_values,\n",
    "                                    self.ibc_fb_cond['Neumann'].x],\n",
    "                                  axis=1),\n",
    "                                  training=True)\n",
    "                pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                                  s_values)\n",
    "                fb_neu_target = -tf.one_hot(\n",
    "                    tf.math.argmin( s_values, axis=1),\n",
    "                    depth=n_dim\n",
    "                    )\n",
    "                fb_neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc_fb-fb_neu_target)\n",
    "                    )\n",
    "            else:\n",
    "                fb_neu_loss = 0\n",
    "            #Compute final loss\n",
    "            fb_loss = self.params['fb_weight'][0] * fb_init_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "\n",
    "            #--------------- Compute PINN losses\n",
    "            #Compute unsupervised loss\n",
    "            s_values = self.fb(tf.concat([self.t_f_total], axis=-1),\n",
    "                               training=False)\n",
    "            temp = tf.reduce_sum(tf.cast(self.x_f_total < s_values,\n",
    "                                         dtype=self.DTYPE),\n",
    "                                axis=-1) < tf.ones(self.t_f_total.shape[0])\n",
    "            x_f = self.x_f_total[ temp ]\n",
    "            t_f = tf.reshape(self.t_f_total[ temp ], (-1,1) )\n",
    "            variables = list()\n",
    "            derivatives = list()\n",
    "            for i in range(x_f.shape[1]):\n",
    "                variables.append( x_f[:, i:i+1] )\n",
    "            variables.append( t_f )\n",
    "            with G_Tape(persistent=True,\n",
    "                        watch_accessed_variables=False) as pinn_tape:\n",
    "                #Watch independet variables\n",
    "                for var in variables:\n",
    "                    pinn_tape.watch( var )\n",
    "                pinn_tape.watch(t_f)\n",
    "                u_val = self.mdl(tf.concat(variables, axis=1),\n",
    "                                    training=True)\n",
    "                u_x = pinn_tape.gradient(u_val, x_f)\n",
    "                for i, var in enumerate(variables[:-1]):\n",
    "                    derivatives.append( pinn_tape.gradient(u_val, var) )\n",
    "            unsup_loss = tf.reduce_mean(tf.square(\n",
    "                self.pde(pinn_tape, variables, u_val, derivatives) ))\n",
    "            #Compute Initial Condition\n",
    "            pinn_init = self.mdl(self.ibc_cond['Initial'].x,\n",
    "                                training=True)\n",
    "            if len(pinn_init.shape) > 1:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  tf.expand_dims(self.ibc_cond['Initial'].y,\n",
    "                                                 axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  self.ibc_cond['Initial'].y )\n",
    "                    )\n",
    "            #Compute Dirichlet Boundary Condition\n",
    "            if self.ibc_cond['Dirichlet'] != None:\n",
    "                pinn_dc = self.mdl(self.ibc_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                if len(pinn_dc.shape) > 1:\n",
    "                    dir_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(pinn_dc -\\\n",
    "                                      tf.expand_dims(self.ibc_cond['Dirichlet'].y,\n",
    "                                                     axis=-1 ) )\n",
    "                        )\n",
    "                else:\n",
    "                    dir_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(pinn_dc -\\\n",
    "                                      self.ibc_cond['Dirichlet'].y )\n",
    "                        )\n",
    "            else:\n",
    "                dir_loss = 0\n",
    "            #Compute Neumann Boundary Condition\n",
    "            if self.ibc_cond['Neumann'] != None:\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_tape:\n",
    "                    neu_tape.watch(self.ibc_cond['Neumann'].x)\n",
    "                    pinn_nc = self.mdl(tf.concat([self.ibc_cond['Neumann'].x,\n",
    "                                                  self.ibc_cond['Neumann'].t],\n",
    "                                                axis=1),\n",
    "                                        training=True)\n",
    "                pinn_nc = neu_tape.gradient(pinn_nc, self.ibc_cond['Neumann'].x)\n",
    "                neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc-self.ibc_cond['Neumann'].y)\n",
    "                    )\n",
    "            else:\n",
    "                neu_loss = 0\n",
    "\n",
    "            #--------------- Compute total loss\n",
    "            pinn_loss = (self.params['pde_weight'] * unsup_loss) +\\\n",
    "            self.params['sup_weight'][0] * init_loss +\\\n",
    "            self.params['sup_weight'][1] * dir_loss +\\\n",
    "            self.params['sup_weight'][2] * neu_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "        #Compute gradient and apply optimizers\n",
    "        gradient = mdl_tape.gradient(pinn_loss,self.mdl.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(gradient,self.mdl.trainable_variables))\n",
    "        #Return losses\n",
    "        final_fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "        final_pinn_loss = unsup_loss + init_loss +\\\n",
    "         dir_loss + neu_loss + fb_dir_loss + fb_neu_loss\n",
    "        return (unsup_loss, init_loss, dir_loss, neu_loss, fb_init_loss,\n",
    "                fb_dir_loss, fb_neu_loss, final_fb_loss, final_pinn_loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_fb_solo(self):\n",
    "        #--------------- Compute Free Boundary losses\n",
    "        with G_Tape(watch_accessed_variables=False) as fb_tape:\n",
    "            #Watch free boundary weights\n",
    "            fb_tape.watch(self.fb.trainable_variables)\n",
    "            #Compute Initial Free Boundary Condition\n",
    "            fb_init = self.fb(self.ibc_fb_cond['Initial'].x,\n",
    "                                  training=True)\n",
    "            fb_init_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_init-self.ibc_fb_cond['Initial'].y)\n",
    "                )\n",
    "            #Compute Dirichlet Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Dirichlet'] != None:\n",
    "                #Compute Free Boundary values\n",
    "                s_values = self.fb(self.ibc_fb_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                fb_dc = self.mdl(tf.concat(\n",
    "                    [s_values,\n",
    "                      self.ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                      training=True)\n",
    "                fb_dir_target = tf.nn.relu(\n",
    "                    tf.ones_like(\n",
    "                        s_values[:,-1]\n",
    "                        ) * K - tf.math.reduce_min(s_values, axis=1)\n",
    "                )\n",
    "                fb_dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(fb_dc - fb_dir_target)\n",
    "                    )\n",
    "            else:\n",
    "                fb_dir_loss = 0\n",
    "            #Compute Neumann Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Neumann'] != None:\n",
    "                s_values = self.fb(self.ibc_fb_cond['Neumann'].x,\n",
    "                                    training=True)\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                    neu_fb_tape.watch(s_values)\n",
    "                    pinn_nc_fb = self.mdl(\n",
    "                        tf.concat([s_values,\n",
    "                                    self.ibc_fb_cond['Neumann'].x],\n",
    "                                  axis=1),\n",
    "                                  training=True)\n",
    "                pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                                  s_values)\n",
    "                fb_neu_target = -tf.one_hot(\n",
    "                    tf.math.argmin( s_values, axis=1),\n",
    "                    depth=n_dim\n",
    "                    )\n",
    "                fb_neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc_fb-fb_neu_target)\n",
    "                    )\n",
    "            else:\n",
    "                fb_neu_loss = 0\n",
    "            #Compute final loss\n",
    "            fb_loss = self.params['fb_weight'][0] * fb_init_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "        #Compute gradient and apply optimizers for free boundary\n",
    "        gradient_fb = fb_tape.gradient(fb_loss,\n",
    "                                      self.fb.trainable_variables)\n",
    "        self.fb_opt.apply_gradients( zip(gradient_fb,\n",
    "                                      self.fb.trainable_variables) )\n",
    "        #Return losses\n",
    "        final_fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "        return fb_init_loss, fb_dir_loss, fb_neu_loss, final_fb_loss\n",
    "\n",
    "    def fit(self, wandb_run=None):\n",
    "        #Early warning initialization\n",
    "        self.early_warning = {'Target':np.inf,\n",
    "                              'n_steps':0,\n",
    "                              'top_mdl':None,\n",
    "                              'weights':None}\n",
    "        old_top_mdl, old_weights = None, None\n",
    "        #Training\n",
    "        self.u_losses, self.i_losses = list(), list()\n",
    "        self.d_losses, self.n_losses = list(), list()\n",
    "        self.b_i_losses = list()\n",
    "        self.b_d_losses, self.b_n_losses = list(), list()\n",
    "        self.b_losses, self.p_losses = list(), list()\n",
    "        print_base = \"{:<10}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}\"\n",
    "        if self.params['fb_freezing'] == None:\n",
    "            for epoch in tqdm(range(self.params['epochs']),\n",
    "                              desc='PINNs - Training'):\n",
    "                if epoch == 0:\n",
    "                    print(print_base.format('Epoch', 'Unsupervised', 'Initial',\n",
    "                                            'Dirichlet', 'Neumann',\n",
    "                                            'FB_Init', 'FB_Dir', 'FB_Neu',\n",
    "                                            'Free Boundary', 'Total'))\n",
    "                    print('\\n')\n",
    "                #Case 1: more mdl steps for a single fb step\n",
    "                for _ in range(self.params['steps_fb_per_pde'] -1):\n",
    "                    self.train_mdl_solo();\n",
    "                #Case 2: more fb steps for a single mdl step\n",
    "                for _ in range(0, self.params['steps_fb_per_pde'] +1, -1):\n",
    "                    self.train_fb_solo();\n",
    "                u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l =\\\n",
    "                self.train_step()\n",
    "                u_l, i_l = np.array(u_l), np.array(i_l)\n",
    "                d_l, n_l = np.array(d_l), np.array(n_l)\n",
    "                b_i_l = np.array(b_i_l)\n",
    "                b_d_l, b_n_l = np.array(b_d_l), np.array(b_n_l)\n",
    "                b_l, p_l = np.array(b_l), np.array(p_l)\n",
    "                if epoch % self.params['verbose'] == 0:\n",
    "                    print(print_base.format(epoch+1, format(u_l, '.20f')[:10],\n",
    "                                            format(i_l, '.20f')[:10],\n",
    "                                            format(d_l, '.20f')[:10],\n",
    "                                            format(n_l, '.20f')[:10],\n",
    "                                            format(b_i_l, '.20f')[:10],\n",
    "                                            format(b_d_l, '.20f')[:10],\n",
    "                                            format(b_n_l, '.20f')[:10],\n",
    "                                            format(b_l, '.20f')[:10],\n",
    "                                            format(p_l, '.20f')[:10]))\n",
    "                self.u_losses.append(u_l)\n",
    "                self.i_losses.append(i_l)\n",
    "                self.d_losses.append(d_l)\n",
    "                self.n_losses.append(n_l)\n",
    "                self.b_i_losses.append(b_i_l)\n",
    "                self.b_d_losses.append(b_d_l)\n",
    "                self.b_n_losses.append(b_d_l)\n",
    "                self.b_losses.append(b_l)\n",
    "                self.p_losses.append(p_l)\n",
    "                #Eventually, update wandb\n",
    "                if wandb_run != None:\n",
    "                    wandb_run.log({'Unsupervised':u_l,\n",
    "                                  'Supervised':i_l + d_l + n_l,\n",
    "                                  'Total':p_l,\n",
    "                                   'Free Boundary':b_l,\n",
    "                                   'Initial':i_l,\n",
    "                                   'Dirichlet':d_l,\n",
    "                                   'Neumann':n_l,\n",
    "                                   'FB_Init':b_i_l,\n",
    "                                   'FB_Dir':b_d_l,\n",
    "                                   'FB_Neu':b_n_l})\n",
    "                #Check for the early warning\n",
    "                if p_l <= self.early_warning['Target']:\n",
    "                    self.early_warning['Target'] = p_l\n",
    "                    self.early_warning['n_steps'] = 0\n",
    "                    self.early_warning['top_mdl'] = old_top_mdl\n",
    "                    self.early_warning['weights'] = old_weights\n",
    "                else:\n",
    "                    self.early_warning['n_steps'] += 1\n",
    "                    if self.early_warning['n_steps'] >= self.params['patience']:\n",
    "                        break\n",
    "                #Save model and weights for next step early warning\n",
    "                old_top_mdl = tf.keras.models.clone_model( self.mdl )\n",
    "                old_weights = self.mdl.get_weights()\n",
    "        else:\n",
    "            #Before freezing, both mdl and fb are training\n",
    "            for epoch in tqdm(range(self.params['fb_freezing']),\n",
    "                              desc='PINNs - Training'):\n",
    "                if epoch == 0:\n",
    "                    print(print_base.format('Epoch', 'Unsupervised', 'Initial',\n",
    "                                            'Dirichlet', 'Neumann',\n",
    "                                            'FB_Init', 'FB_Dir', 'FB_Neu',\n",
    "                                            'Free Boundary', 'Total'))\n",
    "                    print('\\n')\n",
    "                #Case 1: more mdl steps for a single fb step\n",
    "                for _ in range(self.params['steps_fb_per_pde'] -1):\n",
    "                    self.train_mdl_solo();\n",
    "                #Case 2: more fb steps for a single mdl step\n",
    "                for _ in range(0, self.params['steps_fb_per_pde'] +1, -1):\n",
    "                    self.train_fb_solo();\n",
    "                u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l =\\\n",
    "                self.train_step()\n",
    "                u_l, i_l = np.array(u_l), np.array(i_l)\n",
    "                d_l, n_l = np.array(d_l), np.array(n_l)\n",
    "                b_i_l = np.array(b_i_l)\n",
    "                b_d_l, b_n_l = np.array(b_d_l), np.array(b_n_l)\n",
    "                b_l, p_l = np.array(b_l), np.array(p_l)\n",
    "                if epoch % self.params['verbose'] == 0:\n",
    "                    print(print_base.format(epoch+1, format(u_l, '.20f')[:10],\n",
    "                                            format(i_l, '.20f')[:10],\n",
    "                                            format(d_l, '.20f')[:10],\n",
    "                                            format(n_l, '.20f')[:10],\n",
    "                                            format(b_i_l, '.20f')[:10],\n",
    "                                            format(b_d_l, '.20f')[:10],\n",
    "                                            format(b_n_l, '.20f')[:10],\n",
    "                                            format(b_l, '.20f')[:10],\n",
    "                                            format(p_l, '.20f')[:10]))\n",
    "                self.u_losses.append(u_l)\n",
    "                self.i_losses.append(i_l)\n",
    "                self.d_losses.append(d_l)\n",
    "                self.n_losses.append(n_l)\n",
    "                self.b_i_losses.append(b_i_l)\n",
    "                self.b_d_losses.append(b_d_l)\n",
    "                self.b_n_losses.append(b_d_l)\n",
    "                self.b_losses.append(b_l)\n",
    "                self.p_losses.append(p_l)\n",
    "                #Eventually, update wandb\n",
    "                if wandb_run != None:\n",
    "                    wandb_run.log({'Unsupervised':u_l,\n",
    "                                  'Supervised':i_l + d_l + n_l,\n",
    "                                  'Total':p_l,\n",
    "                                   'Free Boundary':b_l,\n",
    "                                   'Initial':i_l,\n",
    "                                   'Dirichlet':d_l,\n",
    "                                   'Neumann':n_l,\n",
    "                                   'FB_Init':b_i_l,\n",
    "                                   'FB_Dir':b_d_l,\n",
    "                                   'FB_Neu':b_n_l})\n",
    "                #Check for the early warning\n",
    "                if p_l <= self.early_warning['Target']:\n",
    "                    self.early_warning['Target'] = p_l\n",
    "                    self.early_warning['n_steps'] = 0\n",
    "                    self.early_warning['top_mdl'] = old_top_mdl\n",
    "                    self.early_warning['weights'] = old_weights\n",
    "                else:\n",
    "                    self.early_warning['n_steps'] += 1\n",
    "                    if self.early_warning['n_steps'] >= self.params['patience']:\n",
    "                        break\n",
    "                #Save model and weights for next step early warning\n",
    "                old_top_mdl = tf.keras.models.clone_model( self.mdl )\n",
    "                old_weights = self.mdl.get_weights()\n",
    "            #Now, freeze fb and train only mdl\n",
    "            for epoch in tqdm(range(self.params['fb_freezing'],\n",
    "                                    self.params['epochs']),\n",
    "                              desc='PINNs - Training; Free Boundary Fixed'):\n",
    "                u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l =\\\n",
    "                self.train_mdl_solo()\n",
    "                u_l, i_l = np.array(u_l), np.array(i_l)\n",
    "                d_l, n_l = np.array(d_l), np.array(n_l)\n",
    "                b_i_l = np.array(b_i_l)\n",
    "                b_d_l, b_n_l = np.array(b_d_l), np.array(b_n_l)\n",
    "                b_l, p_l = np.array(b_l), np.array(p_l)\n",
    "                if epoch % self.params['verbose'] == 0:\n",
    "                    print(print_base.format(epoch+1, format(u_l, '.20f')[:10],\n",
    "                                            format(i_l, '.20f')[:10],\n",
    "                                            format(d_l, '.20f')[:10],\n",
    "                                            format(n_l, '.20f')[:10],\n",
    "                                            format(b_i_l, '.20f')[:10],\n",
    "                                            format(b_d_l, '.20f')[:10],\n",
    "                                            format(b_n_l, '.20f')[:10],\n",
    "                                            format(b_l, '.20f')[:10],\n",
    "                                            format(p_l, '.20f')[:10]))\n",
    "                self.u_losses.append(u_l)\n",
    "                self.i_losses.append(i_l)\n",
    "                self.d_losses.append(d_l)\n",
    "                self.n_losses.append(n_l)\n",
    "                self.b_i_losses.append(b_i_l)\n",
    "                self.b_d_losses.append(b_d_l)\n",
    "                self.b_n_losses.append(b_d_l)\n",
    "                self.b_losses.append(b_l)\n",
    "                self.p_losses.append(p_l)\n",
    "                #Eventually, update wandb\n",
    "                if wandb_run != None:\n",
    "                    wandb_run.log({'Unsupervised':u_l,\n",
    "                                  'Supervised':i_l + d_l + n_l,\n",
    "                                  'Total':p_l,\n",
    "                                   'Free Boundary':b_l,\n",
    "                                   'Initial':i_l,\n",
    "                                   'Dirichlet':d_l,\n",
    "                                   'Neumann':n_l,\n",
    "                                   'FB_Init':b_i_l,\n",
    "                                   'FB_Dir':b_d_l,\n",
    "                                   'FB_Neu':b_n_l})\n",
    "                #Check for the early warning\n",
    "                if p_l <= self.early_warning['Target']:\n",
    "                    self.early_warning['Target'] = p_l\n",
    "                    self.early_warning['n_steps'] = 0\n",
    "                    self.early_warning['top_mdl'] = old_top_mdl\n",
    "                    self.early_warning['weights'] = old_weights\n",
    "                else:\n",
    "                    self.early_warning['n_steps'] += 1\n",
    "                    if self.early_warning['n_steps'] >= self.params['patience']:\n",
    "                        break\n",
    "                #Save model and weights for next step early warning\n",
    "                old_top_mdl = tf.keras.models.clone_model( self.mdl )\n",
    "                old_weights = self.mdl.get_weights()\n",
    "        #Recover information about optimal epoch in early warning\n",
    "        self.mdl = tf.keras.models.clone_model( self.early_warning['top_mdl'] )\n",
    "        self.mdl.set_weights(self.early_warning['weights'])\n",
    "        top_epoch = epoch+1 - self.early_warning[\"n_steps\"]\n",
    "        print(f'Best loss achieved at step {top_epoch}')\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.figure( figsize=(12,8) )\n",
    "        plt.semilogy(self.u_losses, label='Unsupervised')\n",
    "        plt.semilogy(np.array(self.i_losses) +\\\n",
    "                     np.array(self.d_losses) +\\\n",
    "                     np.array(self.n_losses),\n",
    "                     label='Supervised')\n",
    "        plt.semilogy(self.b_losses, label='Free Boundary')\n",
    "        plt.semilogy(self.p_losses, label='PINN')\n",
    "        plt.legend()\n",
    "        plt.title('Losses')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_unsupervised_test(self, test_sampler, test_ibc_cond,\n",
    "                               test_ibc_fb_cond, to_print=True, output=False):\n",
    "        #--------------- Compute Free Boundary losses\n",
    "        #Compute Initial Free Boundary Condition\n",
    "        if test_ibc_fb_cond['Initial'] != None:\n",
    "            fb_init = self.fb(test_ibc_fb_cond['Initial'].x,\n",
    "                                  training=False)\n",
    "            fb_init_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_init-test_ibc_fb_cond['Initial'].y)\n",
    "                )\n",
    "        else:\n",
    "            fb_init_loss = 0\n",
    "        #Compute Dirichlet Free Boundary Condition\n",
    "        if test_ibc_fb_cond['Dirichlet'] != None:\n",
    "            #Compute Free Boundary values\n",
    "            s_values = self.fb(test_ibc_fb_cond['Dirichlet'].x,\n",
    "                                training=True)\n",
    "            fb_dc = self.mdl(tf.concat(\n",
    "                [s_values,\n",
    "                  test_ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                  training=True)\n",
    "            fb_dir_target = tf.nn.relu(\n",
    "                tf.ones_like(\n",
    "                    s_values[:,-1]\n",
    "                    ) * K - tf.math.reduce_min(s_values, axis=1)\n",
    "            )\n",
    "            fb_dir_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_dc - fb_dir_target)\n",
    "                )\n",
    "        else:\n",
    "            fb_dir_loss = 0\n",
    "        #Compute Neumann Free Boundary Condition\n",
    "        if test_ibc_fb_cond['Neumann'] != None:\n",
    "            s_values = self.fb(test_ibc_fb_cond['Neumann'].x,\n",
    "                                training=True)\n",
    "            with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                neu_fb_tape.watch(s_values)\n",
    "                pinn_nc_fb = self.mdl(\n",
    "                    tf.concat([s_values,\n",
    "                                test_ibc_fb_cond['Neumann'].x],\n",
    "                              axis=1),\n",
    "                              training=True)\n",
    "            pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                              s_values)\n",
    "            fb_neu_target = -tf.one_hot(\n",
    "                tf.math.argmin( s_values, axis=1),\n",
    "                depth=n_dim\n",
    "                )\n",
    "            fb_neu_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(pinn_nc_fb-fb_neu_target)\n",
    "                )\n",
    "        else:\n",
    "            fb_neu_loss = 0\n",
    "        #Compute final loss\n",
    "        fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "\n",
    "        #--------------- Compute PINN losses\n",
    "        #Compute unsupervised loss\n",
    "        s_values = self.fb(tf.concat([test_sampler.t], axis=-1),\n",
    "                            training=False)\n",
    "        temp = tf.reduce_sum(tf.cast(test_sampler.x < s_values,\n",
    "                                      dtype=self.DTYPE),\n",
    "                            axis=-1) < tf.ones(test_sampler.t.shape[0])\n",
    "        x_f = test_sampler.x[ temp ]\n",
    "        t_f = tf.reshape(test_sampler.t[ temp ], (-1,1) )\n",
    "        variables = list()\n",
    "        derivatives = list()\n",
    "        for i in range(x_f.shape[1]):\n",
    "            variables.append( x_f[:, i:i+1] )\n",
    "        variables.append( t_f )\n",
    "        with G_Tape(persistent=True,\n",
    "                    watch_accessed_variables=False) as pinn_tape:\n",
    "            #Watch independet variables\n",
    "            for var in variables:\n",
    "                pinn_tape.watch( var )\n",
    "            pinn_tape.watch(t_f)\n",
    "            u_val = self.mdl(tf.concat(variables, axis=1),\n",
    "                                training=True)\n",
    "            u_x = pinn_tape.gradient(u_val, x_f)\n",
    "            for i, var in enumerate(variables[:-1]):\n",
    "                derivatives.append( pinn_tape.gradient(u_val, var) )\n",
    "        unsup_loss = tf.reduce_mean(tf.square(\n",
    "            self.pde(pinn_tape, variables, u_val, derivatives) ))\n",
    "        #Compute Initial Condition\n",
    "        if test_ibc_cond['Initial'] != None:\n",
    "            pinn_init = self.mdl(test_ibc_cond['Initial'].x,\n",
    "                                  training=False)\n",
    "            if len(pinn_init.shape) > 1:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  tf.expand_dims(test_ibc_cond['Initial'].y,\n",
    "                                                 axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  test_ibc_cond['Initial'].y )\n",
    "                    )\n",
    "        else:\n",
    "            init_loss = 0\n",
    "        #Compute Dirichlet Boundary Condition\n",
    "        if test_ibc_cond['Dirichlet'] != None:\n",
    "            pinn_dc = self.mdl(test_ibc_cond['Dirichlet'].x,\n",
    "                                training=True)\n",
    "            if len(pinn_dc.shape) > 1:\n",
    "                dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_dc -\\\n",
    "                                  tf.expand_dims(test_ibc_cond['Dirichlet'].y,\n",
    "                                                 axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_dc -\\\n",
    "                                  test_ibc_cond['Dirichlet'].y )\n",
    "                    )\n",
    "        else:\n",
    "            dir_loss = 0\n",
    "        #Compute Neumann Boundary Condition\n",
    "        if test_ibc_cond['Neumann'] != None:\n",
    "            with G_Tape(watch_accessed_variables=False) as neu_tape:\n",
    "                neu_tape.watch(test_ibc_cond['Neumann'].x)\n",
    "                pinn_nc = self.mdl(tf.concat([test_ibc_cond['Neumann'].x,\n",
    "                                              test_ibc_cond['Neumann'].t],\n",
    "                                            axis=1),\n",
    "                                    training=False)\n",
    "            pinn_nc = neu_tape.gradient(pinn_nc, test_ibc_cond['Neumann'].x)\n",
    "            neu_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(pinn_nc-test_ibc_cond['Neumann'].y)\n",
    "                )\n",
    "        else:\n",
    "            neu_loss = 0\n",
    "\n",
    "        #--------------- Compute total loss\n",
    "        pinn_loss = unsup_loss + init_loss + dir_loss +\\\n",
    "        neu_loss + fb_dir_loss + fb_neu_loss\n",
    "\n",
    "        u_l, i_l = np.array(unsup_loss), np.array(init_loss)\n",
    "        d_l, n_l = np.array(dir_loss), np.array(neu_loss)\n",
    "        b_i_l = np.array(fb_init_loss)\n",
    "        b_d_l, b_n_l = np.array(fb_dir_loss), np.array(fb_neu_loss)\n",
    "        b_l, p_l = np.array(fb_loss), np.array(pinn_loss)\n",
    "\n",
    "        if to_print:\n",
    "            print_base = \"{:<10}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}\"\n",
    "            print(print_base.format('', 'Unsupervised', 'Initial',\n",
    "                                    'Dirichlet', 'Neumann', 'FB_Init', 'FB_Dir',\n",
    "                                    'FB_Neu', 'Free Boundary', 'Total'))\n",
    "            print(print_base.format('', format(u_l, '.20f')[:10],\n",
    "                                    format(i_l, '.20f')[:10],\n",
    "                                    format(d_l, '.20f')[:10],\n",
    "                                    format(n_l, '.20f')[:10],\n",
    "                                    format(b_i_l, '.20f')[:10],\n",
    "                                    format(b_d_l, '.20f')[:10],\n",
    "                                    format(b_n_l, '.20f')[:10],\n",
    "                                    format(b_l, '.20f')[:10],\n",
    "                                    format(p_l, '.20f')[:10]))\n",
    "        if output:\n",
    "            return u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l\n"
   ],
   "id": "d7922f861b22095a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example",
   "id": "2ae0c29c173d2a57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-18T17:39:38.289028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay as ex_d\n",
    "my_lr = ex_d(1e-2, 320, 0.975, staircase=False)\n",
    "fb_lr = ex_d(1e-2, 80, 0.975, staircase=False)\n",
    "\n",
    "params = {'sample_method':'sobol',\n",
    "          'layers':[n_dim+1, 20, 20, 20, 20, 20, 20, 20, 20, 1],\n",
    "          'activation':'tanh',\n",
    "          'output_act':'linear', 'initializer':'glorot_normal',\n",
    "          'fb_layers':[1, 100, 100, 100, n_dim], 'fb_activation':'tanh',\n",
    "          'fb_output_act':'linear', 'fb_initializer':'glorot_normal',\n",
    "          'lr':my_lr, 'optimizer':'rmsprop',\n",
    "          'fb_lr':fb_lr, 'fb_optimizer':'rmsprop', 'steps_fb_per_pde':4,\n",
    "          'pde_weight':1, 'epochs':15000, 'verbose':100}\n",
    "\n",
    "my_pinn = FreeBoundary_PINN(params, pde, pinn_conditions,\n",
    "                            fb_conditions, lb, ub, N_f=120000, DTYPE=DTYPE)\n",
    "\n",
    "START = time.time()\n",
    "my_pinn.fit()\n",
    "train_time = time.time() - START\n",
    "my_pinn.plot_losses()\n",
    "\n",
    "START = time.time()\n",
    "values = my_pinn.plot_unsupervised_test(test_sampler, pinn_cond_test,\n",
    "                                        fb_cond_test, output=True)\n",
    "test_time = time.time() - START\n"
   ],
   "id": "49be3bd6516f3dca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINNs - Training:   0%|          | 0/15000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e937647c34014e328769a525e797d6ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Unsupervised   Initial        Dirichlet      Neumann        FB_Init        FB_Dir         FB_Neu         Free Boundary  Total          \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "1         0.00217668     12.6619749     14.0454292     0.00000000     96.2858352     29.5317935     0.37270227     126.190330     56.6140747     \n",
      "101       0.06323869     1.06593942     0.90398234     0.00000000     0.56724703     0.01674182     0.30657500     0.89056384     2.35647726     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 19\u001B[0m\n\u001B[0;32m     15\u001B[0m my_pinn \u001B[38;5;241m=\u001B[39m FreeBoundary_PINN(params, pde, pinn_conditions,\n\u001B[0;32m     16\u001B[0m                             fb_conditions, lb, ub, N_f\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m120000\u001B[39m, DTYPE\u001B[38;5;241m=\u001B[39mDTYPE)\n\u001B[0;32m     18\u001B[0m START \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 19\u001B[0m \u001B[43mmy_pinn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m train_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m START\n\u001B[0;32m     21\u001B[0m my_pinn\u001B[38;5;241m.\u001B[39mplot_losses()\n",
      "Cell \u001B[1;32mIn[8], line 581\u001B[0m, in \u001B[0;36mFreeBoundary_PINN.fit\u001B[1;34m(self, wandb_run)\u001B[0m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msteps_fb_per_pde\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    579\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_fb_solo();\n\u001B[0;32m    580\u001B[0m u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l \u001B[38;5;241m=\u001B[39m\\\n\u001B[1;32m--> 581\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    582\u001B[0m u_l, i_l \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(u_l), np\u001B[38;5;241m.\u001B[39marray(i_l)\n\u001B[0;32m    583\u001B[0m d_l, n_l \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(d_l), np\u001B[38;5;241m.\u001B[39marray(n_l)\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2953\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2954\u001B[0m   (graph_function,\n\u001B[0;32m   2955\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1849\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1851\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1852\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1853\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1854\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1855\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1856\u001B[0m     args,\n\u001B[0;32m   1857\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1858\u001B[0m     executing_eagerly)\n\u001B[0;32m   1859\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mF:\\anaconda3\\envs\\PINN\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

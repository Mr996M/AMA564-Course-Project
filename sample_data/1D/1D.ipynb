{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1D",
   "id": "5afb769df253a82b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define problem, initial and boundary conditions",
   "id": "28957cca79e83f8e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-19T12:25:49.609894Z",
     "start_time": "2025-04-19T12:25:45.147805Z"
    }
   },
   "source": [
    "\n",
    "import time\n",
    "import wandb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import pi, exp\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_dim = 1\n",
    "\n",
    "#Define global variables\n",
    "r = 0.01\n",
    "T = 3\n",
    "K = 10\n",
    "sigma = 0.05\n",
    "DTYPE = 'float32'\n",
    "\n",
    "#Fix seeds\n",
    "random_seed = 2\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\PINN\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T12:25:52.473628Z",
     "start_time": "2025-04-19T12:25:52.454261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Sampler_IBC():\n",
    "    def __init__(self, lb, ub, cond=None, N_points=100,\n",
    "                 method='uniform', grid=None, split=False, DTYPE='float64'):\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.cond = cond\n",
    "        self.DTYPE = DTYPE\n",
    "        self.sample(N_points, method, grid, split)\n",
    "\n",
    "    def sample(self, N_points, method, grid, split):\n",
    "        if method == 'uniform':\n",
    "            x_ibc = np.random.uniform(0, 1, size=(N_points, self.ub.shape[0]))\n",
    "            x_ibc = self.lb + (self.ub - self.lb)*x_ibc\n",
    "        elif method == 'latin':\n",
    "            from pyDOE import lhs\n",
    "            x_ibc = self.lb + (self.ub - self.lb)*lhs(self.ub.shape[0],N_points)\n",
    "        elif method == 'sobol':\n",
    "            import sobol\n",
    "            x_ibc = sobol.sample(dimension=self.ub.shape[0], n_points=N_points)\n",
    "            x_ibc = self.lb + (self.ub - self.lb)*x_ibc\n",
    "        elif method == 'equi':\n",
    "            x_ibc = np.linspace(self.lb, self.ub, N_points)\n",
    "        elif method == 'grid':\n",
    "            x_ibc = np.linspace(self.lb, self.ub, N_points).T\n",
    "            temp_final = list()\n",
    "            for val in x_ibc[0]:\n",
    "                temp_final.append( [val] )\n",
    "            dim = 1\n",
    "            while dim < x_ibc.shape[0]:\n",
    "                temp = list()\n",
    "                for t1 in range(x_ibc.shape[1]):\n",
    "                    for t2 in range(len(temp_final)):\n",
    "                        temp_val = temp_final[t2].copy()\n",
    "                        temp_val.append( x_ibc[dim, t1] )\n",
    "                        temp.append( temp_val )\n",
    "                temp_final = temp\n",
    "                dim += 1\n",
    "            x_ibc = np.array(temp_final)\n",
    "        elif method == 'grid_old':\n",
    "            idx = np.random.choice(range(grid.shape[0]),N_points,replace=False)\n",
    "            x_ibc = grid[idx]\n",
    "\n",
    "        if self.cond != None:\n",
    "            y_ibc = self.cond(x_ibc)\n",
    "            self.y = tf.cast(tf.Variable(y_ibc, trainable=False ),\n",
    "                             self.DTYPE)\n",
    "        if split:\n",
    "            x_ibc, t_ibc = x_ibc[:, :-1], x_ibc[:, -1:]\n",
    "            self.t = tf.cast(tf.Variable(t_ibc, trainable=False ),\n",
    "                             self.DTYPE)\n",
    "        self.x = tf.cast(tf.Variable(x_ibc, trainable=False ),\n",
    "                         self.DTYPE)\n"
   ],
   "id": "6482683f405e9b62",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T12:25:56.288660Z",
     "start_time": "2025-04-19T12:25:55.274459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Define domain boundaries\n",
    "lb = np.array([0., 0.])\n",
    "ub = np.array([3.*K, T])\n",
    "\n",
    "#Define conditions\n",
    "def h_1(inp):\n",
    "    res = list()\n",
    "    for inp_val in inp:\n",
    "        res.append( K - inp_val[0] )\n",
    "    return np.array(res)\n",
    "\n",
    "def h_2(inp):\n",
    "    res = - np.ones( inp.shape[0] )\n",
    "    return res\n",
    "\n",
    "def g(inp):\n",
    "    res = np.zeros( inp.shape[0] )\n",
    "    return np.array(res)\n",
    "\n",
    "def u_0(inp):\n",
    "    res = list()\n",
    "    for inp_val in inp:\n",
    "        x, t = inp_val\n",
    "        res.append( np.max([0, K-x]) )\n",
    "    return np.array(res)\n",
    "\n",
    "def s_0(inp):\n",
    "    res = np.ones( inp.shape[0] ) * K\n",
    "    return np.array(res)\n",
    "\n",
    "#Point sampling\n",
    "N_to_sample = 300\n",
    "\n",
    "#---------------- PDE Conditions\n",
    "print('PDE COnditions\\n')\n",
    "#Initial\n",
    "init_sampler = Sampler_IBC(np.array([0., T]),\n",
    "                           np.array([3.*K, T]),\n",
    "                           u_0, N_to_sample, DTYPE=DTYPE, method='sobol' )\n",
    "print( f'x: {init_sampler.x.shape}     y: {init_sampler.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "dir_sampler = Sampler_IBC(np.array([3.*K, 0.]), np.array([3.*K, T]),\n",
    "                          g, N_to_sample, DTYPE=DTYPE, method='sobol' )\n",
    "print( f'x: {dir_sampler.x.shape}     y: {dir_sampler.y.shape}' )\n",
    "\n",
    "#Neumann\n",
    "print('No')\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "print('\\nFree Boundary COnditions\\n')\n",
    "#Initial\n",
    "init_fb_sampler = Sampler_IBC(np.array([T]), np.array([T]),\n",
    "                              s_0, 1, DTYPE=DTYPE )\n",
    "print( f't: {init_fb_sampler.x.shape}     y: {init_fb_sampler.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "dir_fb_sampler = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             None, N_to_sample, DTYPE=DTYPE, method='sobol' )\n",
    "print( f't: {dir_fb_sampler.x.shape}' )\n",
    "\n",
    "#Neumann\n",
    "neu_fb_sampler = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             h_2, N_to_sample, DTYPE=DTYPE, method='sobol' )\n",
    "print( f't: {neu_fb_sampler.x.shape}     y: {neu_fb_sampler.y.shape}' )\n",
    "\n",
    "#---------------- Conditions passed to PINN\n",
    "pinn_conditions = {'Initial':init_sampler,\n",
    "                   'Dirichlet':dir_sampler,\n",
    "                   'Neumann':None}\n",
    "fb_conditions = {'Initial':init_fb_sampler,\n",
    "                 'Dirichlet':dir_fb_sampler,\n",
    "                 'Neumann':neu_fb_sampler}\n"
   ],
   "id": "b143d561c227a546",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE COnditions\n",
      "\n",
      "x: (300, 2)     y: (300,)\n",
      "x: (300, 2)     y: (300,)\n",
      "No\n",
      "\n",
      "Free Boundary COnditions\n",
      "\n",
      "t: (1, 1)     y: (1,)\n",
      "t: (300, 1)\n",
      "t: (300, 1)     y: (300,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T12:26:47.486093Z",
     "start_time": "2025-04-19T12:26:02.474205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "test_sampler = Sampler_IBC(lb, ub, cond=None, DTYPE=DTYPE,\n",
    "                           N_points=1000000, method='uniform', split=True)\n",
    "\n",
    "#Point sampling\n",
    "sample_to_test = 1000\n",
    "\n",
    "#---------------- PDE Conditions\n",
    "print('PDE COnditions\\n')\n",
    "#Initial\n",
    "init_sampler_test = Sampler_IBC(np.array([0., T]),\n",
    "                           np.array([3.*K, T]),\n",
    "                           u_0, sample_to_test, DTYPE=DTYPE, method='uniform' )\n",
    "print( f'x: {init_sampler_test.x.shape}     y: {init_sampler_test.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "dir_sampler_test = Sampler_IBC(np.array([3.*K, 0.]), np.array([3.*K, T]),\n",
    "                          g, sample_to_test, DTYPE=DTYPE, method='uniform' )\n",
    "print( f'x: {dir_sampler_test.x.shape}     y: {dir_sampler_test.y.shape}' )\n",
    "\n",
    "#Neumann\n",
    "print('No')\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "print('\\nFree Boundary COnditions\\n')\n",
    "#Initial\n",
    "init_fb_sampler_test = Sampler_IBC(np.array([T]), np.array([T]),\n",
    "                              s_0, 1, DTYPE=DTYPE, method='uniform' )\n",
    "print( f't: {init_fb_sampler_test.x.shape}     y: {init_fb_sampler_test.y.shape}' )\n",
    "\n",
    "#Dirichlet\n",
    "dir_fb_sampler_test = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             None, sample_to_test, DTYPE=DTYPE, method='uniform' )\n",
    "print( f't: {dir_fb_sampler_test.x.shape}' )\n",
    "\n",
    "#Neumann\n",
    "neu_fb_sampler_test = Sampler_IBC(np.array([0.]), np.array([T]),\n",
    "                             h_2, sample_to_test, DTYPE=DTYPE, method='uniform' )\n",
    "print( f't: {neu_fb_sampler_test.x.shape}     y: {neu_fb_sampler_test.y.shape}' )\n",
    "\n",
    "#---------------- Conditions passed to PINN\n",
    "pinn_cond_test = {'Initial':init_sampler_test,\n",
    "                   'Dirichlet':dir_sampler_test,\n",
    "                   'Neumann':None}\n",
    "fb_cond_test = {'Initial':init_fb_sampler_test,\n",
    "                 'Dirichlet':dir_fb_sampler_test,\n",
    "                 'Neumann':neu_fb_sampler_test}\n"
   ],
   "id": "97d18401642690e4",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m test_sampler \u001B[38;5;241m=\u001B[39m Sampler_IBC(lb, ub, cond\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, DTYPE\u001B[38;5;241m=\u001B[39mDTYPE,\n\u001B[0;32m      3\u001B[0m                            N_points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000000\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m'\u001B[39m, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#Point sampling\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m sample_to_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m#---------------- PDE Conditions\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPDE COnditions\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[4], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m test_sampler \u001B[38;5;241m=\u001B[39m Sampler_IBC(lb, ub, cond\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, DTYPE\u001B[38;5;241m=\u001B[39mDTYPE,\n\u001B[0;32m      3\u001B[0m                            N_points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000000\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m'\u001B[39m, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#Point sampling\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m sample_to_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m#---------------- PDE Conditions\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPDE COnditions\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_39_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_39_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_39_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_39_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_39_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mF:\\JetBrains\\PyCharm 2024.3.4\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\JetBrains\\PyCharm 2024.3.4\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:02:37.872349Z",
     "start_time": "2025-04-19T08:02:36.361382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#---------------- PDE Conditions\n",
    "# initial\n",
    "init_S_t = init_sampler.x.numpy()\n",
    "init_P = init_sampler.y.numpy()\n",
    "init_header = \"underlying asset price, time, price\"\n",
    "init_data = np.hstack([init_S_t, init_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_init_data.csv\", init_data, delimiter=\", \", header=init_header)\n",
    "\n",
    "# dirichlet\n",
    "dir_S_t = dir_sampler.x.numpy()\n",
    "dir_P = dir_sampler.y.numpy()\n",
    "dir_header = \"time, underlying asset price, price\"\n",
    "dir_data = np.hstack([dir_S_t, dir_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_dir_data.csv\", dir_data, delimiter=\", \", header=dir_header)\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "# initial_fb\n",
    "init_fb_S_t = init_fb_sampler.x.numpy()\n",
    "init_fb_P = init_fb_sampler.y.numpy()\n",
    "init_fb_header = \"time, underlying asset price\"\n",
    "init_fb_data = np.hstack([init_fb_S_t, init_fb_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_init_fb_data.csv\", init_fb_data, delimiter=\", \", header=init_fb_header)\n",
    "\n",
    "# dirichlet_fb\n",
    "dir_fb_header = \"underlying asset price\"\n",
    "dir_fb_data = dir_fb_sampler.x.numpy()\n",
    "np.savetxt(f\"1D_dir_fb_data.csv\", dir_fb_data, delimiter=\", \", header=dir_fb_header)\n",
    "\n",
    "# neumann_fb\n",
    "neu_fb_S_t = neu_fb_sampler.x.numpy()\n",
    "neu_fb_P = neu_fb_sampler.y.numpy()\n",
    "neu_fb_header = \"underlying asset price, price\"\n",
    "neu_fb_data = np.hstack([neu_fb_S_t, neu_fb_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_neu_fb_data.csv\", neu_fb_data, delimiter=\", \", header=neu_fb_header)\n",
    "\n",
    "############## test ##############\n",
    "#---------------- PDE Conditions\n",
    "# the whole data\n",
    "test_data = test_sampler.x.numpy()  #only underlying asset price, without time\n",
    "test_header = \"underlying asset price\"\n",
    "np.savetxt(f\"1D_test_data.csv\", test_data, delimiter=\", \", header=test_header)\n",
    "\n",
    "# initial_test\n",
    "init_test_S_t = init_sampler_test.x.numpy()\n",
    "init_test_P = init_sampler_test.y.numpy()\n",
    "init_test_header = \"underlying asset price, time, price\"\n",
    "init_test_data = np.hstack([init_test_S_t, init_test_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_test_init_data.csv\", init_test_data, delimiter=\", \", header=init_test_header)\n",
    "\n",
    "# dirichlet_test\n",
    "dir_test_S_t = dir_sampler_test.x.numpy()\n",
    "dir_test_P = dir_sampler_test.y.numpy()\n",
    "dir_test_header = \"time, underlying asset price, price\"\n",
    "dir_test_data = np.hstack([dir_test_S_t, dir_test_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_test_dir_data.csv\", dir_test_data, delimiter=\", \", header=dir_test_header)\n",
    "\n",
    "#---------------- Free Boundary Conditions\n",
    "# initial_fb_test\n",
    "init_fb_test_S_t = init_fb_sampler_test.x.numpy()\n",
    "init_fb_test_P = init_fb_sampler_test.y.numpy()\n",
    "init_fb_test_header = \"time, underlying asset price\"\n",
    "init_fb_test_data = np.hstack([init_fb_test_S_t, init_fb_test_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_test_init_fb_data.csv\", init_fb_test_data, delimiter=\", \", header=init_fb_test_header)\n",
    "\n",
    "# dirichlet_fb_test\n",
    "dir_fb_test_data = dir_fb_sampler_test.x.numpy()\n",
    "dir_fb_test_header = \"underlying asset price\"\n",
    "np.savetxt(f\"1D_test_dir_fb_data.csv\", dir_fb_test_data, delimiter=\", \", header=dir_fb_test_header)\n",
    "\n",
    "# neumann_fb_test\n",
    "neu_fb_test_S_t = neu_fb_sampler_test.x.numpy()\n",
    "neu_fb_test_P = neu_fb_sampler_test.y.numpy()\n",
    "neu_fb_test_header = \"underlying asset price, price\"\n",
    "neu_fb_test_data = np.hstack([neu_fb_test_S_t, neu_fb_test_P.reshape(-1, 1)])\n",
    "np.savetxt(f\"1D_test_neu_fb_data.csv\", neu_fb_test_data, delimiter=\", \", header=neu_fb_test_header)\n"
   ],
   "id": "116ea5b65b356642",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PINN",
   "id": "690fe2641dd590e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "#Define PDE\n",
    "def pde(tape, xs, ts, u_val, u_x):\n",
    "    u_xx = tape.gradient(u_x, xs)\n",
    "    u_t = tape.gradient(u_val, ts)\n",
    "    del(tape)\n",
    "    u_val = tf.cast(u_val, DTYPE)\n",
    "    f = (r * xs * u_x) + u_t + (sigma**2 * xs**2 * u_xx)/2 - (r * u_val)\n",
    "    return f\n"
   ],
   "id": "12248d2872893743"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import GradientTape as G_Tape\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.initializers import GlorotNormal, GlorotUniform\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "\n",
    "class FreeBoundary_PINN():\n",
    "\n",
    "    def __init__(self, params, pde, ibc_cond, ibc_fb_cond, lb, ub,\n",
    "                 N_f=10000, N_fb_ibc=150, DTYPE='float64', coll_points=None):\n",
    "        self.params = params\n",
    "        self.DTYPE = DTYPE\n",
    "        self.Default_Params()\n",
    "        #Set seed\n",
    "        if self.params['seed'] != None:\n",
    "            tf.keras.utils.set_random_seed( self.params['seed'] )\n",
    "            tf.config.experimental.enable_op_determinism()\n",
    "        #Define pde\n",
    "        self.pde = pde\n",
    "        #Define intial and boundary conditions\n",
    "        self.ibc_cond = ibc_cond\n",
    "        self.ibc_fb_cond = ibc_fb_cond\n",
    "        #All needed for points sampling\n",
    "        self.lb = tf.Variable(lb, trainable=False)\n",
    "        self.ub = tf.Variable(ub, trainable=False)\n",
    "        if coll_points == None:\n",
    "            self.N_f = N_f\n",
    "            self.Sample_Points()\n",
    "        else:\n",
    "            self.x_f = coll_points[0]\n",
    "            self.t_f = coll_points[1]\n",
    "        self.N_fb_ibc = N_fb_ibc\n",
    "        #Initialize the class: define the network\n",
    "        self.Define_Regularizer()\n",
    "        self.Define_Initializer()\n",
    "        self.Define_Optimizer()\n",
    "        self.Create_Network()\n",
    "        self.Create_FB_Network()\n",
    "\n",
    "    def Default_Params(self):\n",
    "        target = self.params.keys()\n",
    "        if 'seed' not in target:\n",
    "            self.params['seed'] = None\n",
    "        if 'optimizer' not in target:\n",
    "            self.params['optimizer'] = 'Adam'\n",
    "        if 'reg_type' not in target:\n",
    "            self.params['reg_type'] = None\n",
    "        if 'initializer' not in target:\n",
    "            self.params['initializer'] = 'glorot_normal'\n",
    "        if 'activation' not in target:\n",
    "            self.params['activation'] = 'tanh'\n",
    "        if 'output_act' not in target:\n",
    "            self.params['output_act'] = 'linear'\n",
    "        if 'pde_weight' not in target:\n",
    "            self.params['pde_weight'] = 1.\n",
    "        if 'sup_weight' not in target:\n",
    "            self.params['sup_weight'] = [1., 1., 1.]\n",
    "        if 'fb_weight' not in target:\n",
    "            self.params['fb_weight'] = [1., 1., 1.]\n",
    "        if 'patience' not in target:\n",
    "            self.params['patience'] = np.inf\n",
    "        if 'sample_method' not in target:\n",
    "            self.params['sample_method'] = 'uniform'\n",
    "        if 'fb_output_act' not in target:\n",
    "            self.params['fb_output_act'] = 'linear'\n",
    "        if 'fb_activation' not in target:\n",
    "            self.params['fb_activation'] = 'tanh'\n",
    "        if 'verbose' not in target:\n",
    "            self.params['verbose'] = 1\n",
    "        if 'steps_fb_per_pde' not in target:\n",
    "            self.params['steps_fb_per_pde'] = 1\n",
    "        if 'fb_freezing' not in target:\n",
    "            self.params['fb_freezing'] = None\n",
    "\n",
    "    def Define_Regularizer(self):\n",
    "        if self.params['reg_type'] == 'l1':\n",
    "            self.regularizer = l1( self.params['reg'] )\n",
    "        elif self.params['reg_type'] == 'l2':\n",
    "            self.regularizer = l2( self.params['reg'] )\n",
    "        elif self.params['reg_type'] == 'l1_l2':\n",
    "            self.regularizer = l1_l2( self.params['reg'][0],\n",
    "                                      self.params['reg'][1] )\n",
    "        else:\n",
    "            self.regularizer = None\n",
    "\n",
    "    def Define_Initializer(self):\n",
    "        if self.params['initializer'] == 'glorot_normal':\n",
    "            self.initializer = GlorotNormal()\n",
    "        elif self.params['initializer'] == 'glorot_uniform':\n",
    "            self.initializer = GlorotUniform()\n",
    "        else:\n",
    "            self.initializer = None\n",
    "\n",
    "    def Define_Optimizer(self):\n",
    "        temp = self.params['optimizer']\n",
    "        if temp.lower() == 'adam':\n",
    "            self.opt = Adam( self.params['lr'] )\n",
    "        elif temp.lower() == 'rmsprop':\n",
    "            self.opt = RMSprop( self.params['lr'] )\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer {temp} not recognized\")\n",
    "\n",
    "    def Create_Network(self):\n",
    "        input_layer = Input(shape=self.params['layers'][0],\n",
    "                            name = 'Input')\n",
    "        x = Dense(units=self.params['layers'][1],\n",
    "                  activation=self.params['activation'],\n",
    "                  kernel_initializer=self.initializer,\n",
    "                  kernel_regularizer=self.regularizer,\n",
    "                  name='Dense_1')(input_layer)\n",
    "        for layer in range(2, len(self.params['layers'])-1):\n",
    "            x = Dense(units=self.params['layers'][layer],\n",
    "                      activation=self.params['activation'],\n",
    "                      kernel_initializer=self.initializer,\n",
    "                      kernel_regularizer=self.regularizer,\n",
    "                      name=f'Dense_{layer}')(x)\n",
    "        output = Dense(units=self.params['layers'][-1],\n",
    "                       activation=self.params['output_act'],\n",
    "                       kernel_initializer=self.initializer,\n",
    "                       kernel_regularizer=self.regularizer,\n",
    "                       name='Output')(x)\n",
    "        self.mdl = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    def Create_FB_Network(self):\n",
    "        input_layer = Input(shape=self.params['fb_layers'][0],\n",
    "                            name = 'Input')\n",
    "        x = Dense(units=self.params['fb_layers'][1],\n",
    "                  activation=self.params['fb_activation'],\n",
    "                  kernel_initializer=self.initializer,\n",
    "                  kernel_regularizer=self.regularizer,\n",
    "                  name='Dense_1')(input_layer)\n",
    "        for layer in range(2, len(self.params['fb_layers'])-1):\n",
    "            x = Dense(units=self.params['fb_layers'][layer],\n",
    "                      activation=self.params['fb_activation'],\n",
    "                      kernel_initializer=self.initializer,\n",
    "                      kernel_regularizer=self.regularizer,\n",
    "                      name=f'Dense_{layer}')(x)\n",
    "        output = Dense(units=self.params['fb_layers'][-1],\n",
    "                       activation=self.params['fb_output_act'],\n",
    "                       kernel_initializer=self.initializer,\n",
    "                       kernel_regularizer=self.regularizer,\n",
    "                       name='Output')(x)\n",
    "        self.fb = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    def Sample_Points(self):\n",
    "        #According to the selected method, sample collocation points\n",
    "        method = self.params['sample_method']\n",
    "        if method == 'latin':\n",
    "            from pyDOE import lhs\n",
    "            cps = self.lb + (self.ub - self.lb)*lhs(self.ub.shape[0], self.N_f)\n",
    "        elif method == 'uniform':\n",
    "            cps = np.random.uniform(0, 1, size=(self.N_f, self.ub.shape[0]))\n",
    "            cps = self.lb + (self.ub - self.lb)*cps\n",
    "        elif method == 'sobol':\n",
    "            import sobol\n",
    "            cps = sobol.sample(dimension=self.ub.shape[0], n_points=self.N_f)\n",
    "            cps = self.lb + (self.ub - self.lb)*cps\n",
    "        else:\n",
    "            raise ValueError(f'Sampling method {method} not recognized')\n",
    "        #Return collocation points as tf tensors\n",
    "        self.x_f_total = tf.cast(tf.Variable(cps[:, :-1], trainable=False),\n",
    "                                 self.DTYPE)\n",
    "        self.t_f_total = tf.cast(tf.Variable(cps[:, -1:], trainable=False),\n",
    "                                 self.DTYPE)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self):\n",
    "        with G_Tape(watch_accessed_variables=False) as mdl_tape:\n",
    "            #Watch solution weights\n",
    "            mdl_tape.watch(self.mdl.trainable_variables)\n",
    "            #--------------- Compute Free Boundary losses\n",
    "            with G_Tape(watch_accessed_variables=False) as fb_tape:\n",
    "                #Watch free boundary weights\n",
    "                fb_tape.watch(self.fb.trainable_variables)\n",
    "                #Compute Initial Free Boundary Condition\n",
    "                fb_init = self.fb(self.ibc_fb_cond['Initial'].x,\n",
    "                                      training=True)\n",
    "                fb_init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(fb_init-self.ibc_fb_cond['Initial'].y)\n",
    "                    )\n",
    "                #Compute Dirichlet Free Boundary Condition\n",
    "                if self.ibc_fb_cond['Dirichlet'] != None:\n",
    "                    #Compute Free Boundary values\n",
    "                    s_values = self.fb(self.ibc_fb_cond['Dirichlet'].x,\n",
    "                                       training=True)\n",
    "                    fb_dc = self.mdl(tf.concat(\n",
    "                        [s_values,\n",
    "                         self.ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                         training=True)\n",
    "                    fb_dir_target = tf.nn.relu(\n",
    "                        tf.ones_like(\n",
    "                            s_values\n",
    "                            ) * K - s_values\n",
    "                    )\n",
    "                    fb_dir_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(fb_dc - fb_dir_target)\n",
    "                        )\n",
    "                else:\n",
    "                    fb_dir_loss = 0\n",
    "                #Compute Neumann Free Boundary Condition\n",
    "                if self.ibc_fb_cond['Neumann'] != None:\n",
    "                    s_values = self.fb(self.ibc_fb_cond['Neumann'].x,\n",
    "                                       training=True)\n",
    "                    with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                        neu_fb_tape.watch(s_values)\n",
    "                        pinn_nc_fb = self.mdl(\n",
    "                            tf.concat([s_values,\n",
    "                                       self.ibc_fb_cond['Neumann'].x],\n",
    "                                      axis=1),\n",
    "                                      training=True)\n",
    "                    pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                                      s_values)\n",
    "                    fb_neu_loss = tf.math.reduce_mean(\n",
    "                        tf.math.square(pinn_nc_fb-self.ibc_fb_cond['Neumann'].y)\n",
    "                        )\n",
    "                else:\n",
    "                    fb_neu_loss = 0\n",
    "                #Compute final loss\n",
    "                fb_loss = self.params['fb_weight'][0] * fb_init_loss +\\\n",
    "                self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "                self.params['fb_weight'][2] * fb_neu_loss\n",
    "            #Compute gradient and apply optimizers for free boundary\n",
    "            gradient_fb = fb_tape.gradient(fb_loss,\n",
    "                                          self.fb.trainable_variables)\n",
    "            self.opt.apply_gradients( zip(gradient_fb,\n",
    "                                          self.fb.trainable_variables) )\n",
    "\n",
    "            #--------------- Compute PINN losses\n",
    "            #Compute unsupervised loss\n",
    "            s_values = self.fb(tf.concat([self.t_f_total], axis=-1),\n",
    "                               training=False)\n",
    "            x_f = tf.reshape(self.x_f_total[ self.x_f_total > s_values ],\n",
    "                             (-1,1) )\n",
    "            t_f = tf.reshape(self.t_f_total[ self.x_f_total > s_values ],\n",
    "                             (-1,1) )\n",
    "            with G_Tape(persistent=True,\n",
    "                        watch_accessed_variables=False) as pinn_tape:\n",
    "                #Watch independet variables\n",
    "                pinn_tape.watch(x_f)\n",
    "                pinn_tape.watch(t_f)\n",
    "                #Apply u function for unsupervised\n",
    "                u_val = self.mdl(tf.stack([x_f, t_f], axis=1),\n",
    "                                training=True)\n",
    "                u_x = pinn_tape.gradient(u_val, x_f)\n",
    "            unsup_loss = tf.reduce_mean(tf.square(\n",
    "                self.pde(pinn_tape, x_f, t_f, u_val, u_x) ))\n",
    "            #Compute Initial Condition\n",
    "            pinn_init = self.mdl(self.ibc_cond['Initial'].x,\n",
    "                                training=True)\n",
    "            if len(pinn_init.shape) > 1:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  tf.expand_dims(self.ibc_cond['Initial'].y,\n",
    "                                                 axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  self.ibc_cond['Initial'].y )\n",
    "                    )\n",
    "            #Compute Dirichlet Boundary Condition\n",
    "            if self.ibc_cond['Dirichlet'] != None:\n",
    "                pinn_dc = self.mdl(self.ibc_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_dc-self.ibc_cond['Dirichlet'].y)\n",
    "                    )\n",
    "            else:\n",
    "                dir_loss = 0\n",
    "            #Compute Neumann Boundary Condition\n",
    "            if self.ibc_cond['Neumann'] != None:\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_tape:\n",
    "                    neu_tape.watch(self.ibc_cond['Neumann'].x)\n",
    "                    pinn_nc = self.mdl(tf.concat([self.ibc_cond['Neumann'].x,\n",
    "                                                  self.ibc_cond['Neumann'].t],\n",
    "                                                axis=1),\n",
    "                                        training=True)\n",
    "                pinn_nc = neu_tape.gradient(pinn_nc, self.ibc_cond['Neumann'].x)\n",
    "                neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc-self.ibc_cond['Neumann'].y)\n",
    "                    )\n",
    "            else:\n",
    "                neu_loss = 0\n",
    "\n",
    "            #--------------- Compute total loss\n",
    "            pinn_loss = (self.params['pde_weight'] * unsup_loss) +\\\n",
    "            self.params['sup_weight'][0] * init_loss +\\\n",
    "            self.params['sup_weight'][1] * dir_loss +\\\n",
    "            self.params['sup_weight'][2] * neu_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "        #Compute gradient and apply optimizers\n",
    "        gradient = mdl_tape.gradient(pinn_loss,self.mdl.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(gradient,self.mdl.trainable_variables))\n",
    "        #Return losses\n",
    "        final_fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "        final_pinn_loss = unsup_loss + init_loss +\\\n",
    "         dir_loss + neu_loss + fb_dir_loss + fb_neu_loss\n",
    "        return (unsup_loss, init_loss, dir_loss, neu_loss, fb_init_loss,\n",
    "                fb_dir_loss, fb_neu_loss, final_fb_loss, final_pinn_loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_mdl_solo(self):\n",
    "        with G_Tape(watch_accessed_variables=False) as mdl_tape:\n",
    "            #Watch solution weights\n",
    "            mdl_tape.watch(self.mdl.trainable_variables)\n",
    "            #--------------- Compute Free Boundary losses\n",
    "            #Compute Initial Free Boundary Condition\n",
    "            fb_init = self.fb(self.ibc_fb_cond['Initial'].x,\n",
    "                                  training=True)\n",
    "            fb_init_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_init-self.ibc_fb_cond['Initial'].y)\n",
    "                )\n",
    "            #Compute Dirichlet Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Dirichlet'] != None:\n",
    "                #Compute Free Boundary values\n",
    "                s_values = self.fb(self.ibc_fb_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                fb_dc = self.mdl(tf.concat(\n",
    "                    [s_values,\n",
    "                      self.ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                      training=True)\n",
    "                fb_dir_target = tf.nn.relu(\n",
    "                    tf.ones_like(\n",
    "                        s_values\n",
    "                        ) * K - s_values\n",
    "                )\n",
    "                fb_dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(fb_dc - fb_dir_target)\n",
    "                    )\n",
    "            else:\n",
    "                fb_dir_loss = 0\n",
    "            #Compute Neumann Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Neumann'] != None:\n",
    "                s_values = self.fb(self.ibc_fb_cond['Neumann'].x,\n",
    "                                    training=True)\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                    neu_fb_tape.watch(s_values)\n",
    "                    pinn_nc_fb = self.mdl(\n",
    "                        tf.concat([s_values,\n",
    "                                    self.ibc_fb_cond['Neumann'].x],\n",
    "                                  axis=1),\n",
    "                                  training=True)\n",
    "                pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                                  s_values)\n",
    "                fb_neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc_fb-self.ibc_fb_cond['Neumann'].y)\n",
    "                    )\n",
    "            else:\n",
    "                fb_neu_loss = 0\n",
    "            #Compute final loss\n",
    "            fb_loss = self.params['fb_weight'][0] * fb_init_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "\n",
    "            #--------------- Compute PINN losses\n",
    "            #Compute unsupervised loss\n",
    "            s_values = self.fb(tf.concat([self.t_f_total], axis=-1),\n",
    "                               training=False)\n",
    "            x_f = tf.reshape(self.x_f_total[ self.x_f_total > s_values ],\n",
    "                             (-1,1) )\n",
    "            t_f = tf.reshape(self.t_f_total[ self.x_f_total > s_values ],\n",
    "                             (-1,1) )\n",
    "            with G_Tape(persistent=True,\n",
    "                        watch_accessed_variables=False) as pinn_tape:\n",
    "                #Watch independet variables\n",
    "                pinn_tape.watch(x_f)\n",
    "                pinn_tape.watch(t_f)\n",
    "                #Apply u function for unsupervised\n",
    "                u_val = self.mdl(tf.stack([x_f, t_f], axis=1),\n",
    "                                training=True)\n",
    "                u_x = pinn_tape.gradient(u_val, x_f)\n",
    "            unsup_loss = tf.reduce_mean(tf.square(\n",
    "                self.pde(pinn_tape, x_f, t_f, u_val, u_x) ))\n",
    "            #Compute Initial Condition\n",
    "            pinn_init = self.mdl(self.ibc_cond['Initial'].x,\n",
    "                                training=True)\n",
    "            if len(pinn_init.shape) > 1:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  tf.expand_dims(self.ibc_cond['Initial'].y,\n",
    "                                                 axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  self.ibc_cond['Initial'].y )\n",
    "                    )\n",
    "            #Compute Dirichlet Boundary Condition\n",
    "            if self.ibc_cond['Dirichlet'] != None:\n",
    "                pinn_dc = self.mdl(self.ibc_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_dc-self.ibc_cond['Dirichlet'].y)\n",
    "                    )\n",
    "            else:\n",
    "                dir_loss = 0\n",
    "            #Compute Neumann Boundary Condition\n",
    "            if self.ibc_cond['Neumann'] != None:\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_tape:\n",
    "                    neu_tape.watch(self.ibc_cond['Neumann'].x)\n",
    "                    pinn_nc = self.mdl(tf.concat([self.ibc_cond['Neumann'].x,\n",
    "                                                  self.ibc_cond['Neumann'].t],\n",
    "                                                axis=1),\n",
    "                                        training=True)\n",
    "                pinn_nc = neu_tape.gradient(pinn_nc, self.ibc_cond['Neumann'].x)\n",
    "                neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc-self.ibc_cond['Neumann'].y)\n",
    "                    )\n",
    "            else:\n",
    "                neu_loss = 0\n",
    "\n",
    "            #--------------- Compute total loss\n",
    "            pinn_loss = (self.params['pde_weight'] * unsup_loss) +\\\n",
    "            self.params['sup_weight'][0] * init_loss +\\\n",
    "            self.params['sup_weight'][1] * dir_loss +\\\n",
    "            self.params['sup_weight'][2] * neu_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "        #Compute gradient and apply optimizers\n",
    "        gradient = mdl_tape.gradient(pinn_loss,self.mdl.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(gradient,self.mdl.trainable_variables))\n",
    "        #Return losses\n",
    "        final_fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "        final_pinn_loss = unsup_loss + init_loss +\\\n",
    "         dir_loss + neu_loss + fb_dir_loss + fb_neu_loss\n",
    "        return (unsup_loss, init_loss, dir_loss, neu_loss, fb_init_loss,\n",
    "                fb_dir_loss, fb_neu_loss, final_fb_loss, final_pinn_loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_fb_solo(self):\n",
    "        #--------------- Compute Free Boundary losses\n",
    "        with G_Tape(watch_accessed_variables=False) as fb_tape:\n",
    "            #Watch free boundary weights\n",
    "            fb_tape.watch(self.fb.trainable_variables)\n",
    "            #Compute Initial Free Boundary Condition\n",
    "            fb_init = self.fb(self.ibc_fb_cond['Initial'].x,\n",
    "                                  training=True)\n",
    "            fb_init_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_init-self.ibc_fb_cond['Initial'].y)\n",
    "                )\n",
    "            #Compute Dirichlet Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Dirichlet'] != None:\n",
    "                #Compute Free Boundary values\n",
    "                s_values = self.fb(self.ibc_fb_cond['Dirichlet'].x,\n",
    "                                    training=True)\n",
    "                fb_dc = self.mdl(tf.concat(\n",
    "                    [s_values,\n",
    "                      self.ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                      training=True)\n",
    "                fb_dir_target = tf.nn.relu(\n",
    "                    tf.ones_like(\n",
    "                        s_values\n",
    "                        ) * K - s_values\n",
    "                )\n",
    "                fb_dir_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(fb_dc - fb_dir_target)\n",
    "                    )\n",
    "            else:\n",
    "                fb_dir_loss = 0\n",
    "            #Compute Neumann Free Boundary Condition\n",
    "            if self.ibc_fb_cond['Neumann'] != None:\n",
    "                s_values = self.fb(self.ibc_fb_cond['Neumann'].x,\n",
    "                                    training=True)\n",
    "                with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                    neu_fb_tape.watch(s_values)\n",
    "                    pinn_nc_fb = self.mdl(\n",
    "                        tf.concat([s_values,\n",
    "                                    self.ibc_fb_cond['Neumann'].x],\n",
    "                                  axis=1),\n",
    "                                  training=True)\n",
    "                pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                                  s_values)\n",
    "                fb_neu_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_nc_fb-self.ibc_fb_cond['Neumann'].y)\n",
    "                    )\n",
    "            else:\n",
    "                fb_neu_loss = 0\n",
    "            #Compute final loss\n",
    "            fb_loss = self.params['fb_weight'][0] * fb_init_loss +\\\n",
    "            self.params['fb_weight'][1] * fb_dir_loss +\\\n",
    "            self.params['fb_weight'][2] * fb_neu_loss\n",
    "        #Compute gradient and apply optimizers for free boundary\n",
    "        gradient_fb = fb_tape.gradient(fb_loss,\n",
    "                                      self.fb.trainable_variables)\n",
    "        self.opt.apply_gradients( zip(gradient_fb,\n",
    "                                      self.fb.trainable_variables) )\n",
    "        #Return losses\n",
    "        final_fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "        return fb_init_loss, fb_dir_loss, fb_neu_loss, final_fb_loss\n",
    "\n",
    "    def fit(self, wandb_run=None):\n",
    "        #Early warning initialization\n",
    "        self.early_warning = {'Target':np.inf,\n",
    "                              'n_steps':0,\n",
    "                              'top_mdl':None,\n",
    "                              'weights':None}\n",
    "        old_top_mdl, old_weights = None, None\n",
    "        #Training\n",
    "        self.u_losses, self.i_losses = list(), list()\n",
    "        self.d_losses, self.n_losses = list(), list()\n",
    "        self.b_i_losses = list()\n",
    "        self.b_d_losses, self.b_n_losses = list(), list()\n",
    "        self.b_losses, self.p_losses = list(), list()\n",
    "        print_base = \"{:<10}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}\"\n",
    "        if self.params['fb_freezing'] == None:\n",
    "            for epoch in tqdm(range(self.params['epochs']),\n",
    "                              desc='PINNs - Training'):\n",
    "                if epoch == 0:\n",
    "                    print(print_base.format('Epoch', 'Unsupervised', 'Initial',\n",
    "                                            'Dirichlet', 'Neumann',\n",
    "                                            'FB_Init', 'FB_Dir', 'FB_Neu',\n",
    "                                            'Free Boundary', 'Total'))\n",
    "                    print('\\n')\n",
    "                #Case 1: more mdl steps for a single fb step\n",
    "                for _ in range(self.params['steps_fb_per_pde'] -1):\n",
    "                    self.train_mdl_solo();\n",
    "                #Case 2: more fb steps for a single mdl step\n",
    "                for _ in range(0, self.params['steps_fb_per_pde'] +1, -1):\n",
    "                    self.train_fb_solo();\n",
    "                u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l =\\\n",
    "                self.train_step()\n",
    "                u_l, i_l = np.array(u_l), np.array(i_l)\n",
    "                d_l, n_l = np.array(d_l), np.array(n_l)\n",
    "                b_i_l = np.array(b_i_l)\n",
    "                b_d_l, b_n_l = np.array(b_d_l), np.array(b_n_l)\n",
    "                b_l, p_l = np.array(b_l), np.array(p_l)\n",
    "                if epoch % self.params['verbose'] == 0:\n",
    "                    print(print_base.format(epoch+1, format(u_l, '.20f')[:10],\n",
    "                                            format(i_l, '.20f')[:10],\n",
    "                                            format(d_l, '.20f')[:10],\n",
    "                                            format(n_l, '.20f')[:10],\n",
    "                                            format(b_i_l, '.20f')[:10],\n",
    "                                            format(b_d_l, '.20f')[:10],\n",
    "                                            format(b_n_l, '.20f')[:10],\n",
    "                                            format(b_l, '.20f')[:10],\n",
    "                                            format(p_l, '.20f')[:10]))\n",
    "                self.u_losses.append(u_l)\n",
    "                self.i_losses.append(i_l)\n",
    "                self.d_losses.append(d_l)\n",
    "                self.n_losses.append(n_l)\n",
    "                self.b_i_losses.append(b_i_l)\n",
    "                self.b_d_losses.append(b_d_l)\n",
    "                self.b_n_losses.append(b_d_l)\n",
    "                self.b_losses.append(b_l)\n",
    "                self.p_losses.append(p_l)\n",
    "                #Eventually, update wandb\n",
    "                if wandb_run != None:\n",
    "                    wandb_run.log({'Unsupervised':u_l,\n",
    "                                  'Supervised':i_l + d_l + n_l,\n",
    "                                  'Total':p_l,\n",
    "                                   'Free Boundary':b_l,\n",
    "                                   'Initial':i_l,\n",
    "                                   'Dirichlet':d_l,\n",
    "                                   'Neumann':n_l,\n",
    "                                   'FB_Init':b_i_l,\n",
    "                                   'FB_Dir':b_d_l,\n",
    "                                   'FB_Neu':b_n_l})\n",
    "                #Check for the early warning\n",
    "                if p_l <= self.early_warning['Target']:\n",
    "                    self.early_warning['Target'] = p_l\n",
    "                    self.early_warning['n_steps'] = 0\n",
    "                    self.early_warning['top_mdl'] = old_top_mdl\n",
    "                    self.early_warning['weights'] = old_weights\n",
    "                else:\n",
    "                    self.early_warning['n_steps'] += 1\n",
    "                    if self.early_warning['n_steps'] >= self.params['patience']:\n",
    "                        break\n",
    "                #Save model and weights for next step early warning\n",
    "                old_top_mdl = tf.keras.models.clone_model( self.mdl )\n",
    "                old_weights = self.mdl.get_weights()\n",
    "        else:\n",
    "            #Before freezing, both mdl and fb are training\n",
    "            for epoch in tqdm(range(self.params['fb_freezing']),\n",
    "                              desc='PINNs - Training'):\n",
    "                if epoch == 0:\n",
    "                    print(print_base.format('Epoch', 'Unsupervised', 'Initial',\n",
    "                                            'Dirichlet', 'Neumann',\n",
    "                                            'FB_Init', 'FB_Dir', 'FB_Neu',\n",
    "                                            'Free Boundary', 'Total'))\n",
    "                    print('\\n')\n",
    "                #Case 1: more mdl steps for a single fb step\n",
    "                for _ in range(self.params['steps_fb_per_pde'] -1):\n",
    "                    self.train_mdl_solo();\n",
    "                #Case 2: more fb steps for a single mdl step\n",
    "                for _ in range(0, self.params['steps_fb_per_pde'] +1, -1):\n",
    "                    self.train_fb_solo();\n",
    "                u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l =\\\n",
    "                self.train_step()\n",
    "                u_l, i_l = np.array(u_l), np.array(i_l)\n",
    "                d_l, n_l = np.array(d_l), np.array(n_l)\n",
    "                b_i_l = np.array(b_i_l)\n",
    "                b_d_l, b_n_l = np.array(b_d_l), np.array(b_n_l)\n",
    "                b_l, p_l = np.array(b_l), np.array(p_l)\n",
    "                if epoch % self.params['verbose'] == 0:\n",
    "                    print(print_base.format(epoch+1, format(u_l, '.20f')[:10],\n",
    "                                            format(i_l, '.20f')[:10],\n",
    "                                            format(d_l, '.20f')[:10],\n",
    "                                            format(n_l, '.20f')[:10],\n",
    "                                            format(b_i_l, '.20f')[:10],\n",
    "                                            format(b_d_l, '.20f')[:10],\n",
    "                                            format(b_n_l, '.20f')[:10],\n",
    "                                            format(b_l, '.20f')[:10],\n",
    "                                            format(p_l, '.20f')[:10]))\n",
    "                self.u_losses.append(u_l)\n",
    "                self.i_losses.append(i_l)\n",
    "                self.d_losses.append(d_l)\n",
    "                self.n_losses.append(n_l)\n",
    "                self.b_i_losses.append(b_i_l)\n",
    "                self.b_d_losses.append(b_d_l)\n",
    "                self.b_n_losses.append(b_d_l)\n",
    "                self.b_losses.append(b_l)\n",
    "                self.p_losses.append(p_l)\n",
    "                #Eventually, update wandb\n",
    "                if wandb_run != None:\n",
    "                    wandb_run.log({'Unsupervised':u_l,\n",
    "                                  'Supervised':i_l + d_l + n_l,\n",
    "                                  'Total':p_l,\n",
    "                                   'Free Boundary':b_l,\n",
    "                                   'Initial':i_l,\n",
    "                                   'Dirichlet':d_l,\n",
    "                                   'Neumann':n_l,\n",
    "                                   'FB_Init':b_i_l,\n",
    "                                   'FB_Dir':b_d_l,\n",
    "                                   'FB_Neu':b_n_l})\n",
    "                #Check for the early warning\n",
    "                if p_l <= self.early_warning['Target']:\n",
    "                    self.early_warning['Target'] = p_l\n",
    "                    self.early_warning['n_steps'] = 0\n",
    "                    self.early_warning['top_mdl'] = old_top_mdl\n",
    "                    self.early_warning['weights'] = old_weights\n",
    "                else:\n",
    "                    self.early_warning['n_steps'] += 1\n",
    "                    if self.early_warning['n_steps'] >= self.params['patience']:\n",
    "                        break\n",
    "                #Save model and weights for next step early warning\n",
    "                old_top_mdl = tf.keras.models.clone_model( self.mdl )\n",
    "                old_weights = self.mdl.get_weights()\n",
    "            #Now, freeze fb and train only mdl\n",
    "            for epoch in tqdm(range(self.params['fb_freezing'],\n",
    "                                    self.params['epochs']),\n",
    "                              desc='PINNs - Training; Free Boundary Fixed'):\n",
    "                u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l =\\\n",
    "                self.train_mdl_solo()\n",
    "                u_l, i_l = np.array(u_l), np.array(i_l)\n",
    "                d_l, n_l = np.array(d_l), np.array(n_l)\n",
    "                b_i_l = np.array(b_i_l)\n",
    "                b_d_l, b_n_l = np.array(b_d_l), np.array(b_n_l)\n",
    "                b_l, p_l = np.array(b_l), np.array(p_l)\n",
    "                if epoch % self.params['verbose'] == 0:\n",
    "                    print(print_base.format(epoch+1, format(u_l, '.20f')[:10],\n",
    "                                            format(i_l, '.20f')[:10],\n",
    "                                            format(d_l, '.20f')[:10],\n",
    "                                            format(n_l, '.20f')[:10],\n",
    "                                            format(b_i_l, '.20f')[:10],\n",
    "                                            format(b_d_l, '.20f')[:10],\n",
    "                                            format(b_n_l, '.20f')[:10],\n",
    "                                            format(b_l, '.20f')[:10],\n",
    "                                            format(p_l, '.20f')[:10]))\n",
    "                self.u_losses.append(u_l)\n",
    "                self.i_losses.append(i_l)\n",
    "                self.d_losses.append(d_l)\n",
    "                self.n_losses.append(n_l)\n",
    "                self.b_i_losses.append(b_i_l)\n",
    "                self.b_d_losses.append(b_d_l)\n",
    "                self.b_n_losses.append(b_d_l)\n",
    "                self.b_losses.append(b_l)\n",
    "                self.p_losses.append(p_l)\n",
    "                #Eventually, update wandb\n",
    "                if wandb_run != None:\n",
    "                    wandb_run.log({'Unsupervised':u_l,\n",
    "                                  'Supervised':i_l + d_l + n_l,\n",
    "                                  'Total':p_l,\n",
    "                                   'Free Boundary':b_l,\n",
    "                                   'Initial':i_l,\n",
    "                                   'Dirichlet':d_l,\n",
    "                                   'Neumann':n_l,\n",
    "                                   'FB_Init':b_i_l,\n",
    "                                   'FB_Dir':b_d_l,\n",
    "                                   'FB_Neu':b_n_l})\n",
    "                #Check for the early warning\n",
    "                if p_l <= self.early_warning['Target']:\n",
    "                    self.early_warning['Target'] = p_l\n",
    "                    self.early_warning['n_steps'] = 0\n",
    "                    self.early_warning['top_mdl'] = old_top_mdl\n",
    "                    self.early_warning['weights'] = old_weights\n",
    "                else:\n",
    "                    self.early_warning['n_steps'] += 1\n",
    "                    if self.early_warning['n_steps'] >= self.params['patience']:\n",
    "                        break\n",
    "                #Save model and weights for next step early warning\n",
    "                old_top_mdl = tf.keras.models.clone_model( self.mdl )\n",
    "                old_weights = self.mdl.get_weights()\n",
    "        #Recover information about optimal epoch in early warning\n",
    "        self.mdl = tf.keras.models.clone_model( self.early_warning['top_mdl'] )\n",
    "        self.mdl.set_weights(self.early_warning['weights'])\n",
    "        top_epoch = epoch+1 - self.early_warning[\"n_steps\"]\n",
    "        print(f'Best loss achieved at step {top_epoch}')\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.figure( figsize=(12,8) )\n",
    "        plt.semilogy(self.u_losses, label='Unsupervised')\n",
    "        plt.semilogy(np.array(self.i_losses) +\\\n",
    "                     np.array(self.d_losses) +\\\n",
    "                     np.array(self.n_losses),\n",
    "                     label='Supervised')\n",
    "        plt.semilogy(self.b_losses, label='Free Boundary')\n",
    "        plt.semilogy(self.p_losses, label='PINN')\n",
    "        plt.legend()\n",
    "        plt.title('Losses')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_unsupervised_test(self, test_sampler, test_ibc_cond,\n",
    "                               test_ibc_fb_cond, to_print=True, output=False):\n",
    "        #--------------- Compute Free Boundary losses\n",
    "        #Compute Initial Free Boundary Condition\n",
    "        if test_ibc_fb_cond['Initial'] != None:\n",
    "            fb_init = self.fb(test_ibc_fb_cond['Initial'].x,\n",
    "                                  training=False)\n",
    "            fb_init_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_init-test_ibc_fb_cond['Initial'].y)\n",
    "                )\n",
    "        else:\n",
    "            fb_init_loss = 0\n",
    "        #Compute Dirichlet Free Boundary Condition\n",
    "        if test_ibc_fb_cond['Dirichlet'] != None:\n",
    "            #Compute Free Boundary values\n",
    "            s_values = self.fb(test_ibc_fb_cond['Dirichlet'].x,\n",
    "                                training=True)\n",
    "            fb_dc = self.mdl(tf.concat(\n",
    "                [s_values,\n",
    "                  test_ibc_fb_cond['Dirichlet'].x], axis=1),\n",
    "                  training=True)\n",
    "            fb_dir_target = tf.nn.relu(\n",
    "                tf.ones_like(\n",
    "                    s_values\n",
    "                    ) * K - s_values\n",
    "            )\n",
    "            fb_dir_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(fb_dc - fb_dir_target)\n",
    "                )\n",
    "        else:\n",
    "            fb_dir_loss = 0\n",
    "        #Compute Neumann Free Boundary Condition\n",
    "        if test_ibc_fb_cond['Neumann'] != None:\n",
    "            s_values = self.fb(test_ibc_fb_cond['Neumann'].x,\n",
    "                                training=False)\n",
    "            with G_Tape(watch_accessed_variables=False) as neu_fb_tape:\n",
    "                neu_fb_tape.watch(s_values)\n",
    "                pinn_nc_fb = self.mdl(\n",
    "                    tf.concat([s_values,\n",
    "                                test_ibc_fb_cond['Neumann'].x],\n",
    "                              axis=1),\n",
    "                              training=True)\n",
    "            pinn_nc_fb = neu_fb_tape.gradient(pinn_nc_fb,\n",
    "                                              s_values)\n",
    "            fb_neu_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(pinn_nc_fb-test_ibc_fb_cond['Neumann'].y)\n",
    "                )\n",
    "        else:\n",
    "            fb_neu_loss = 0\n",
    "        #Compute final loss\n",
    "        fb_loss = fb_init_loss + fb_dir_loss + fb_neu_loss\n",
    "\n",
    "        #--------------- Compute PINN losses\n",
    "        #Compute unsupervised loss\n",
    "        s_values = self.fb(tf.concat([test_sampler.t], axis=-1),\n",
    "                               training=False)\n",
    "        x_f = tf.reshape(test_sampler.x[ test_sampler.x > s_values ],\n",
    "                          (-1,1) )\n",
    "        t_f = tf.reshape(test_sampler.t[ test_sampler.x > s_values ],\n",
    "                          (-1,1) )\n",
    "        with G_Tape(persistent=True,\n",
    "                    watch_accessed_variables=False) as pinn_tape:\n",
    "            #Watch independet variables\n",
    "            pinn_tape.watch(x_f)\n",
    "            pinn_tape.watch(t_f)\n",
    "            #Apply u function for unsupervised\n",
    "            u_val = self.mdl(tf.stack([x_f, t_f], axis=1),\n",
    "                            training=True)\n",
    "            u_x = pinn_tape.gradient(u_val, x_f)\n",
    "        unsup_loss = tf.reduce_mean(tf.square(\n",
    "            self.pde(pinn_tape, x_f, t_f, u_val, u_x) ))\n",
    "        #Compute Initial Condition\n",
    "        if test_ibc_cond['Initial'] != None:\n",
    "            pinn_init = self.mdl(test_ibc_cond['Initial'].x,\n",
    "                                  training=False)\n",
    "            if len(pinn_init.shape) > 1:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  tf.expand_dims( test_ibc_cond['Initial'].y, axis=-1 ) )\n",
    "                    )\n",
    "            else:\n",
    "                init_loss = tf.math.reduce_mean(\n",
    "                    tf.math.square(pinn_init -\\\n",
    "                                  test_ibc_cond['Initial'].y )\n",
    "                    )\n",
    "        else:\n",
    "            init_loss = 0\n",
    "        #Compute Dirichlet Boundary Condition\n",
    "        if test_ibc_cond['Dirichlet'] != None:\n",
    "            pinn_dc = self.mdl(test_ibc_cond['Dirichlet'].x,\n",
    "                                training=False)\n",
    "            dir_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(pinn_dc-test_ibc_cond['Dirichlet'].y)\n",
    "                )\n",
    "        else:\n",
    "            dir_loss = 0\n",
    "        #Compute Neumann Boundary Condition\n",
    "        if test_ibc_cond['Neumann'] != None:\n",
    "            with G_Tape(watch_accessed_variables=False) as neu_tape:\n",
    "                neu_tape.watch(test_ibc_cond['Neumann'].x)\n",
    "                pinn_nc = self.mdl(tf.concat([test_ibc_cond['Neumann'].x,\n",
    "                                              test_ibc_cond['Neumann'].t],\n",
    "                                            axis=1),\n",
    "                                    training=False)\n",
    "            pinn_nc = neu_tape.gradient(pinn_nc, test_ibc_cond['Neumann'].x)\n",
    "            neu_loss = tf.math.reduce_mean(\n",
    "                tf.math.square(pinn_nc-test_ibc_cond['Neumann'].y)\n",
    "                )\n",
    "        else:\n",
    "            neu_loss = 0\n",
    "\n",
    "        #--------------- Compute total loss\n",
    "        pinn_loss = unsup_loss + init_loss + dir_loss +\\\n",
    "        neu_loss + fb_dir_loss + fb_neu_loss\n",
    "\n",
    "        u_l, i_l = np.array(unsup_loss), np.array(init_loss)\n",
    "        d_l, n_l = np.array(dir_loss), np.array(neu_loss)\n",
    "        b_i_l = np.array(fb_init_loss)\n",
    "        b_d_l, b_n_l = np.array(fb_dir_loss), np.array(fb_neu_loss)\n",
    "        b_l, p_l = np.array(fb_loss), np.array(pinn_loss)\n",
    "\n",
    "        if to_print:\n",
    "            print_base = \"{:<10}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}{:<15}\"\n",
    "            print(print_base.format('', 'Unsupervised', 'Initial',\n",
    "                                    'Dirichlet', 'Neumann', 'FB_Init', 'FB_Dir',\n",
    "                                    'FB_Neu', 'Free Boundary', 'Total'))\n",
    "            print(print_base.format('', format(u_l, '.20f')[:10],\n",
    "                                    format(i_l, '.20f')[:10],\n",
    "                                    format(d_l, '.20f')[:10],\n",
    "                                    format(n_l, '.20f')[:10],\n",
    "                                    format(b_i_l, '.20f')[:10],\n",
    "                                    format(b_d_l, '.20f')[:10],\n",
    "                                    format(b_n_l, '.20f')[:10],\n",
    "                                    format(b_l, '.20f')[:10],\n",
    "                                    format(p_l, '.20f')[:10]))\n",
    "        if output:\n",
    "            return u_l, i_l, d_l, n_l, b_i_l, b_d_l, b_n_l, b_l, p_l\n"
   ],
   "id": "9df968a26830f6f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example",
   "id": "a5eb7dc4988ec6fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay as ex_d\n",
    "my_lr = ex_d(1e-2, 500, 0.9, staircase=False)\n",
    "\n",
    "params = {'sample_method':'sobol',\n",
    "          'layers':[n_dim+1, 20, 20, 20, 20, 20, 20, 20, 20, 1],\n",
    "          'activation':'tanh',\n",
    "          'output_act':'linear', 'initializer':'glorot_normal',\n",
    "          'fb_layers':[1, 100, 100, 100, n_dim], 'fb_activation':'tanh',\n",
    "          'fb_output_act':'linear', 'fb_initializer':'glorot_normal',\n",
    "          'lr':my_lr, 'optimizer':'rmsprop',\n",
    "          'fb_lr':my_lr, 'fb_optimizer':'rmsprop', 'steps_fb_per_pde':20,\n",
    "          'pde_weight':1, 'epochs':4000, 'verbose':50}\n",
    "\n",
    "my_pinn = FreeBoundary_PINN(params, pde, pinn_conditions,\n",
    "                            fb_conditions, lb, ub, N_f=30000, DTYPE=DTYPE)\n",
    "\n",
    "START = time.time()\n",
    "my_pinn.fit()\n",
    "train_time = time.time() - START\n",
    "my_pinn.plot_losses()\n",
    "\n",
    "START = time.time()\n",
    "values = my_pinn.plot_unsupervised_test(test_sampler, pinn_cond_test,\n",
    "                                        fb_cond_test, output=True)\n",
    "test_time = time.time() - START\n"
   ],
   "id": "1dfc9e1ff9a3d793"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
